{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c476bdcd",
   "metadata": {},
   "source": [
    "# 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc62bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================核心模块=====================\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "import orjson\n",
    "import torch\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ============================================================\n",
    "# 配置加载\n",
    "# ============================================================\n",
    "\n",
    "def load_config(config_path: Path) -> dict:\n",
    "    \"\"\"加载YAML配置文件\"\"\"\n",
    "    with config_path.open(\"r\", encoding=\"utf-8\") as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "# ============================================================\n",
    "# 工具函数\n",
    "# ============================================================\n",
    "\n",
    "def find_raw_data_directories(root_directory: Path, search_depth: int) -> List[Path]:\n",
    "    \"\"\"查找包含raw_data的目录\"\"\"\n",
    "    directories = []\n",
    "    to_visit = [(root_directory, 0)]\n",
    "    \n",
    "    while to_visit:\n",
    "        current_dir, current_depth = to_visit.pop()\n",
    "        raw_data_dir = current_dir / \"raw_data\"\n",
    "        \n",
    "        if raw_data_dir.exists() and raw_data_dir.is_dir():\n",
    "            directories.append(current_dir)\n",
    "        \n",
    "        if current_depth < search_depth:\n",
    "            for child in current_dir.iterdir():\n",
    "                if child.is_dir():\n",
    "                    to_visit.append((child, current_depth + 1))\n",
    "    \n",
    "    return directories\n",
    "\n",
    "def collect_images(raw_data_directory: Path) -> List[Path]:\n",
    "    \"\"\"收集目录中的所有图片\"\"\"\n",
    "    extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
    "    image_paths = []\n",
    "    for ext in extensions:\n",
    "        image_paths.extend(raw_data_directory.glob(f\"*{ext}\"))\n",
    "    return sorted(image_paths)\n",
    "\n",
    "def generate_tile_windows(image_height: int, image_width: int, tile_height: int, tile_width: int, overlap_ratio: float) -> List[Tuple[int, int, int, int]]:\n",
    "    \"\"\"生成切片窗口\"\"\"\n",
    "    overlap_ratio = max(0.0, min(0.99, overlap_ratio))\n",
    "    step_height = max(1, int(tile_height * (1.0 - overlap_ratio)))\n",
    "    step_width = max(1, int(tile_width * (1.0 - overlap_ratio)))\n",
    "    \n",
    "    y_starts = list(range(0, max(1, image_height - tile_height + 1), step_height))\n",
    "    x_starts = list(range(0, max(1, image_width - tile_width + 1), step_width))\n",
    "    \n",
    "    # 确保覆盖边缘\n",
    "    last_y = max(0, image_height - tile_height)\n",
    "    last_x = max(0, image_width - tile_width)\n",
    "    if y_starts[-1] != last_y: y_starts.append(last_y)\n",
    "    if x_starts[-1] != last_x: x_starts.append(last_x)\n",
    "    \n",
    "    windows = []\n",
    "    for y in y_starts:\n",
    "        y_end = min(y + tile_height, image_height)\n",
    "        for x in x_starts:\n",
    "            x_end = min(x + tile_width, image_width)\n",
    "            windows.append((x, y, x_end, y_end))\n",
    "    \n",
    "    return windows\n",
    "\n",
    "def run_yolo_on_tiles(model, tiles, offsets, yolo_config, image_stem):\n",
    "    \"\"\"在切片上运行YOLO推理\"\"\"\n",
    "    if not tiles:\n",
    "        return []\n",
    "    \n",
    "    results = model.predict(\n",
    "        tiles,\n",
    "        imgsz=yolo_config[\"image_size\"],\n",
    "        conf=yolo_config[\"confidence_threshold\"],\n",
    "        iou=yolo_config[\"iou_threshold\"],\n",
    "        device=str(yolo_config[\"device\"]),\n",
    "        batch=yolo_config[\"batch_size\"],\n",
    "        workers=yolo_config[\"workers\"],\n",
    "        verbose=yolo_config[\"verbose\"],\n",
    "        save=yolo_config[\"save_results\"],\n",
    "        retina_masks=yolo_config[\"retina_masks\"],\n",
    "    )\n",
    "    \n",
    "    detections = []\n",
    "    for i, result in enumerate(results):\n",
    "        offset_x, offset_y = offsets[i]\n",
    "        \n",
    "        try:\n",
    "            records = orjson.loads(result.to_json())\n",
    "        except Exception:\n",
    "            continue\n",
    "        \n",
    "        for record in records:\n",
    "            segments = record.get(\"segments\", {})\n",
    "            x_vals = segments.get(\"x\", [])\n",
    "            y_vals = segments.get(\"y\", [])\n",
    "            \n",
    "            if not x_vals or not y_vals:\n",
    "                continue\n",
    "            \n",
    "            label = record.get(\"name\", \"\")\n",
    "            score = record.get(\"confidence\", 0.0)\n",
    "            \n",
    "            # 转换到原图坐标系\n",
    "            polygon = []\n",
    "            for local_x, local_y in zip(x_vals, y_vals):\n",
    "                polygon.append([local_x + offset_x, local_y + offset_y])\n",
    "            \n",
    "            if len(polygon) >= 3:  # 至少3个点\n",
    "                detections.append({\n",
    "                    \"image_stem\": image_stem,\n",
    "                    \"label_name\": label,\n",
    "                    \"score\": score,\n",
    "                    \"polygon\": polygon,\n",
    "                    \"object_id\": str(uuid4())\n",
    "                })\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    return detections\n",
    "\n",
    "def process_single_image(image_path, model, processing_config, yolo_config):\n",
    "    \"\"\"处理单张图片\"\"\"\n",
    "    # 读取图片\n",
    "    buffer = np.fromfile(str(image_path), dtype=np.uint8)\n",
    "    if buffer.size == 0:\n",
    "        logger.warning(f\"Empty file: {image_path}\")\n",
    "        return []\n",
    "    \n",
    "    image = cv2.imdecode(buffer, cv2.IMREAD_COLOR)\n",
    "    if image is None:\n",
    "        logger.warning(f\"Failed to decode: {image_path}\")\n",
    "        return []\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # 生成切片\n",
    "    windows = generate_tile_windows(\n",
    "        height, width,\n",
    "        processing_config[\"tile_height\"],\n",
    "        processing_config[\"tile_width\"],\n",
    "        processing_config[\"overlap_ratio\"]\n",
    "    )\n",
    "    \n",
    "    # 分批处理切片\n",
    "    all_detections = []\n",
    "    tiles, offsets = [], []\n",
    "    batch_size = 64  # 每批最大切片数\n",
    "    \n",
    "    for x_start, y_start, x_end, y_end in windows:\n",
    "        tile = image[y_start:y_end, x_start:x_end]\n",
    "        tiles.append(tile)\n",
    "        offsets.append((x_start, y_start))\n",
    "        \n",
    "        if len(tiles) >= batch_size:\n",
    "            batch_detections = run_yolo_on_tiles(model, tiles, offsets, yolo_config, image_path.stem)\n",
    "            all_detections.extend(batch_detections)\n",
    "            tiles, offsets = [], []\n",
    "    \n",
    "    # 处理剩余切片\n",
    "    if tiles:\n",
    "        batch_detections = run_yolo_on_tiles(model, tiles, offsets, yolo_config, image_path.stem)\n",
    "        all_detections.extend(batch_detections)\n",
    "    \n",
    "    return all_detections\n",
    "\n",
    "def process_directory(raw_data_dir, model, processing_config, yolo_config):\n",
    "    \"\"\"处理整个目录\"\"\"\n",
    "    image_paths = collect_images(raw_data_dir)\n",
    "    if not image_paths:\n",
    "        logger.info(f\"No images found in {raw_data_dir}\")\n",
    "        return {}\n",
    "    \n",
    "    detections_by_image = {}\n",
    "    total = len(image_paths)\n",
    "    \n",
    "    for i, image_path in enumerate(image_paths, 1):\n",
    "        logger.info(f\"[{i}/{total}] Processing: {image_path}\")\n",
    "        detections = process_single_image(image_path, model, processing_config, yolo_config)\n",
    "        if detections:\n",
    "            detections_by_image[image_path.stem] = detections\n",
    "    \n",
    "    return detections_by_image\n",
    "\n",
    "def create_coco_dataset(raw_data_dir, detections_by_image, categories):\n",
    "    \"\"\"创建COCO格式数据集\"\"\"\n",
    "    image_paths = collect_images(raw_data_dir)\n",
    "    \n",
    "    # 构建类别映射\n",
    "    category_map = {cat[\"name\"]: cat for cat in categories}\n",
    "    \n",
    "    images, annotations = [], []\n",
    "    image_id, annotation_id = 1, 1\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        stem = image_path.stem\n",
    "        if stem not in detections_by_image:\n",
    "            continue\n",
    "        \n",
    "        # 读取图片尺寸\n",
    "        buffer = np.fromfile(str(image_path), dtype=np.uint8)\n",
    "        image = cv2.imdecode(buffer, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        # 解析文件名中的信息\n",
    "        parts = stem.split(\"_\")\n",
    "        timestamp = f\"{parts[0]}_{parts[1]}\" if len(parts) >= 2 else \"\"\n",
    "        focal_length = int(parts[-1]) if parts and parts[-1].isdigit() else 0\n",
    "        \n",
    "        # 添加图片信息\n",
    "        images.append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": image_path.name,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"timestamp\": timestamp,\n",
    "            \"focal_length_parameter\": focal_length\n",
    "        })\n",
    "        \n",
    "        # 添加标注信息\n",
    "        for detection in detections_by_image[stem]:\n",
    "            category = category_map.get(detection[\"label_name\"])\n",
    "            if not category:\n",
    "                continue\n",
    "            \n",
    "            polygon = detection[\"polygon\"]\n",
    "            # 计算边界框\n",
    "            x_coords = [p[0] for p in polygon]\n",
    "            y_coords = [p[1] for p in polygon]\n",
    "            bbox = [min(x_coords), min(y_coords), max(x_coords)-min(x_coords), max(y_coords)-min(y_coords)]\n",
    "            area = bbox[2] * bbox[3]\n",
    "            \n",
    "            # 展平多边形坐标\n",
    "            segmentation = [coord for point in polygon for coord in point]\n",
    "            \n",
    "            annotations.append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": category[\"id\"],\n",
    "                \"segmentation\": [segmentation],\n",
    "                \"area\": area,\n",
    "                \"bbox\": bbox,\n",
    "                \"iscrowd\": 0,\n",
    "                \"score\": detection[\"score\"],\n",
    "                \"object_id\": detection[\"object_id\"]\n",
    "            })\n",
    "            annotation_id += 1\n",
    "        \n",
    "        image_id += 1\n",
    "    \n",
    "    return {\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": categories\n",
    "    }\n",
    "\n",
    "def save_coco_dataset(coco_data, output_path):\n",
    "    \"\"\"保存COCO数据集\"\"\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    output_path.write_bytes(orjson.dumps(coco_data, option=orjson.OPT_INDENT_2))\n",
    "    logger.info(f\"COCO annotations saved to: {output_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# 主流程\n",
    "# ============================================================\n",
    "\n",
    "def run_pipeline(config_path: Path):\n",
    "    \"\"\"运行完整流程\"\"\"\n",
    "    # 加载配置\n",
    "    config = load_config(config_path)\n",
    "    processing_config = config[\"processing\"]\n",
    "    yolo_config = config[\"yolo\"]\n",
    "    pipeline_config = config[\"pipeline\"]\n",
    "    categories = config[\"categories\"]\n",
    "    \n",
    "    root_dir = Path(pipeline_config[\"input\"][\"root_directory\"])\n",
    "    search_depth = pipeline_config[\"input\"][\"search_depth\"]\n",
    "    \n",
    "    print(f\"Root directory: {root_dir}\")\n",
    "    print(f\"Search depth: {search_depth}\")\n",
    "    \n",
    "    # 查找所有包含raw_data的目录\n",
    "    parent_dirs = find_raw_data_directories(root_dir, search_depth)\n",
    "    if not parent_dirs:\n",
    "        print(\"No directories with 'raw_data' found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Found directories with 'raw_data':\")\n",
    "    for dir_path in parent_dirs:\n",
    "        print(f\"  - {dir_path}\")\n",
    "    \n",
    "    # 加载模型\n",
    "    model = YOLO(yolo_config[\"model_path\"])\n",
    "    \n",
    "    # 处理每个目录\n",
    "    for parent_dir in parent_dirs:\n",
    "        raw_data_dir = parent_dir / \"raw_data\"\n",
    "        \n",
    "        if not collect_images(raw_data_dir):\n",
    "            logger.info(f\"Skipping {raw_data_dir}, no images found\")\n",
    "            continue\n",
    "        \n",
    "        logger.info(f\"=== Processing: {parent_dir} ===\")\n",
    "        \n",
    "        # 运行推理\n",
    "        detections = process_directory(raw_data_dir, model, processing_config, yolo_config)\n",
    "        \n",
    "        if not detections:\n",
    "            logger.info(f\"No detections in {raw_data_dir}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # 创建COCO数据集\n",
    "        coco_data = create_coco_dataset(raw_data_dir, detections, categories)\n",
    "        \n",
    "        # 保存结果\n",
    "        output_dir_name = pipeline_config[\"output\"][\"directory_name\"]\n",
    "        output_file_name = pipeline_config[\"output\"][\"file_name\"]\n",
    "        output_path = parent_dir / output_dir_name / output_file_name\n",
    "        \n",
    "        save_coco_dataset(coco_data, output_path)\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    config_path = Path(\"config.yaml\")  # 你的配置文件路径\n",
    "    run_pipeline(config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
