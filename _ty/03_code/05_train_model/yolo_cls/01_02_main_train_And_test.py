# %% [markdown]
# # è®­ç»ƒåˆ†ç±»æ¨¡å‹

# %%
from ultralytics import YOLO
import wandb
import os

# ========================
# 1. åŸºæœ¬é…ç½®
# ========================
wandb.login(key="957096cc564005d5332d45e2da6a75838e1cc9ac")

PROJECT_NAME = "swd_cls_v1_4datasets"

# ä½ çš„åˆ†ç±»æ•°æ®é›†æ ¹ç›®å½•åˆ—è¡¨
# æ¯ä¸ªè·¯å¾„ä¸‹é¢éœ€è¦æ˜¯ï¼š
#   root/
#     train/classA/...
#     val/classA/...
#     test/classA/...   (å¯é€‰)
DATASETS = [
    # "/workspace/_ty/03_code/05_train_model/yolo_cls/data/data_split_0.4_0.3_0.3", 
    # "/workspace/_ty/03_code/05_train_model/yolo_cls/data/data_split_0.5_0.3_0.2",
    # "/workspace/_ty/03_code/05_train_model/yolo_cls/data/data_split_0.6_0.2_0.2",
    "/workspace/_ty/03_code/05_train_model/yolo_cls/data/data_split_0.6_0.4_0.0",
    "/workspace/_ty/03_code/05_train_model/yolo_cls/data/data_split_0.8_0.2_0.0",
]

batchSizes = [4, 8, 16]

# ä½¿ç”¨ YOLO åˆ†ç±»æ¨¡å‹ï¼ˆæ³¨æ„æ˜¯ -cls.ptï¼‰
models = [
    "yolo11n-cls.pt",
    "yolo11s-cls.pt",
    "yolo11m-cls.pt"
    # éœ€è¦å¯ä»¥åŠ ï¼š , "yolo11l-cls.pt", "yolo11x-cls.pt",
]


# å°å·¥å…·ï¼šä»è·¯å¾„é‡Œæå–ä¸€ä¸ªå¥½è¯»çš„åå­—
def dataset_name_from_path(path: str) -> str:
    return os.path.basename(path.rstrip("/")) or path.replace("/", "_")


# ========================
# 2. å¾ªç¯1ï¼šé»˜è®¤å¢å¼º + seed=42
# ========================
# for data_path in DATASETS:
#     ds_name = dataset_name_from_path(data_path)

#     for modelFile in models:
#         for batch in batchSizes:
#             print(f"\nğŸš€ [CLS-DEFAULT] model={modelFile}, dataset={ds_name}, batch={batch}")

#             model = YOLO(modelFile)

#             try:
#                 model.train(
#                     task="classify",        # æ˜ç¡®æŒ‡å®šåˆ†ç±»ä»»åŠ¡
#                     data=data_path,        # â­ ç›´æ¥ç»™æ ¹ç›®å½•è·¯å¾„ï¼Œä¸æ˜¯ yaml
#                     epochs=1000,
#                     imgsz=640,
#                     batch=batch,
#                     device=0,
#                     workers=4,
#                     project=f"output/{PROJECT_NAME}_seed42",
#                     name=f"{ds_name}_{modelFile}_{batch}",
#                     seed=42,
#                     deterministic=True,
#                 )

#                 # å¦‚æœæ•°æ®é‡Œæœ‰ test/ ç›®å½•ï¼Œå¯ä»¥è¿™æ ·è¯„ä¼°
#                 model.val(
#                     task="classify",
#                     data=data_path,
#                     split="test",   # æ²¡æœ‰ test æ–‡ä»¶å¤¹å°±åˆ æ‰è¿™ä¸ªå‚æ•°
#                     name=f"{ds_name}_{modelFile}_{batch}_test",
#                 )

#             except RuntimeError as e:
#                 if "CUDA out of memory" in str(e):
#                     print(f"âš ï¸ è·³è¿‡: model={modelFile}, dataset={ds_name}, batch={batch} â€”â€” æ˜¾å­˜ä¸è¶³")
#                     continue
#                 else:
#                     raise


# ========================
# 3. å¾ªç¯2ï¼šåŸºæœ¬æ— å¢å¼º + seed=0
# ========================
# for data_path in DATASETS:
#     ds_name = dataset_name_from_path(data_path)

#     for modelFile in models:
#         for batch in batchSizes:
#             print(f"\nğŸš€ [CLS-noAug-seed0] model={modelFile}, dataset={ds_name}, batch={batch}")

#             model = YOLO(modelFile)

#             try:
#                 model.train(
#                     task="classify",
#                     data=data_path,
#                     epochs=1000,
#                     # imgsz=640,
#                     batch=batch,
#                     device=0,
#                     workers=4,
#                     project=f"output/{PROJECT_NAME}_noAug_seed0",
#                     name=f"{ds_name}_{modelFile}_{batch}",

#                     # ====== åˆ†ç±»å¢å¼ºï¼šå°½é‡å…³æ‰ ======
#                     degrees=0.0,
#                     scale=0.0,
#                     shear=0.0,
#                     translate=0.0,

#                     mixup=0.0,
#                     cutmix=0.0,
#                     erasing=0.0,

#                     flipud=0.0,
#                     fliplr=0.0,

#                     seed=0,
#                     deterministic=True,
#                 )

#                 model.val(
#                     task="classify",
#                     data=data_path,
#                     split="test",
#                     name=f"{ds_name}_{modelFile}_{batch}_test",
#                 )

#             except RuntimeError as e:
#                 if "CUDA out of memory" in str(e):
#                     print(f"âš ï¸ è·³è¿‡: model={modelFile}, dataset={ds_name}, batch={batch} â€”â€” æ˜¾å­˜ä¸è¶³")
#                     continue
#                 else:
#                     raise


# ========================
# 4. å¾ªç¯3ï¼šåŸºæœ¬æ— å¢å¼º + seed=42
# ========================
for data_path in DATASETS:
    ds_name = dataset_name_from_path(data_path)

    for modelFile in models:
        for batch in batchSizes:
            print(f"\nğŸš€ [CLS-noAug-seed42] model={modelFile}, dataset={ds_name}, batch={batch}")

            model = YOLO(modelFile)

            try:
                model.train(
                    task="classify",
                    data=data_path,
                    epochs=1000,
                    # imgsz=640,
                    batch=batch,
                    device=0,
                    workers=4,
                    project=f"output/{PROJECT_NAME}_noAug_seed42",
                    name=f"{ds_name}_{modelFile}_{batch}",

                    degrees=0.0,
                    scale=0.0,
                    shear=0.0,
                    translate=0.0,

                    mixup=0.0,
                    cutmix=0.0,
                    erasing=0.0,

                    flipud=0.0,
                    fliplr=0.0,

                    seed=42,
                    deterministic=True,
                )

                model.val(
                    task="classify",
                    data=data_path,
                    split="test",
                    name=f"{ds_name}_{modelFile}_{batch}_test",
                )

            except RuntimeError as e:
                if "CUDA out of memory" in str(e):
                    print(f"âš ï¸ è·³è¿‡: model={modelFile}, dataset={ds_name}, batch={batch} â€”â€” æ˜¾å­˜ä¸è¶³")
                    continue
                else:
                    raise



