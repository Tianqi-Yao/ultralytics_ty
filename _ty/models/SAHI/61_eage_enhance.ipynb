{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a5f36c",
   "metadata": {},
   "source": [
    "# 增强边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c173b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/workspace/models/SAHI/run_v9/tttt\"\n",
    "# path = \"/workspace/models/SAHI/run_v9/ElderFarm1_0625/images/autofocus_rpicam_still/20250620_141212_Center.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cad1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images in /workspace/models/SAHI/run_v9/tttt\n"
     ]
    }
   ],
   "source": [
    "# load folders\n",
    "from pathlib import Path\n",
    "\n",
    "folder = Path(folder_path)\n",
    "in_paths = list(folder.glob(\"*.jpg\")) + list(folder.glob(\"*.png\"))\n",
    "print(f\"Found {len(in_paths)} images in {folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ac1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_paths = [\n",
    "#     # \"/mnt/data/334b0994-4395-4105-9c4e-0731c3b60441.png\",\n",
    "#     # \"/mnt/data/4c2f7d60-45f7-413f-8eb2-74731264cd35.png\",\n",
    "#     path\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992dd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "out_dir = folder_path + \"/enhanced\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f380c87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read /workspace/models/SAHI/run_v9/tttt/HSH4.jpg\n",
      "Failed to read /workspace/models/SAHI/run_v9/tttt/HSH5.jpg\n",
      "Failed to read /workspace/models/SAHI/run_v9/tttt/HSH6.jpg\n",
      "Failed to read /workspace/models/SAHI/run_v9/tttt/HSH7.jpg\n",
      "Failed to read /workspace/models/SAHI/run_v9/tttt/HSH8.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2627.582] global loadsave.cpp:268 findDecoder imread_('/workspace/models/SAHI/run_v9/tttt/HSH4.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@2627.583] global loadsave.cpp:268 findDecoder imread_('/workspace/models/SAHI/run_v9/tttt/HSH5.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@2627.583] global loadsave.cpp:268 findDecoder imread_('/workspace/models/SAHI/run_v9/tttt/HSH6.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@2627.584] global loadsave.cpp:268 findDecoder imread_('/workspace/models/SAHI/run_v9/tttt/HSH7.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@2627.584] global loadsave.cpp:268 findDecoder imread_('/workspace/models/SAHI/run_v9/tttt/HSH8.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "# This script loads two provided trap images, applies a suite of enhancement methods\n",
    "# to make insect-vs-background boundaries clearer, and saves both individual results\n",
    "# and contact sheets for quick comparison. All outputs go to /mnt/data/swd_enhanced.\n",
    "#\n",
    "# Methods included:\n",
    "# - invert\n",
    "# - red_channel_norm\n",
    "# - red_minus_green_norm\n",
    "# - hsv_v_clahe\n",
    "# - lab_l_clahe\n",
    "# - gamma_1p4 (brighten mids)\n",
    "# - gamma_0p7 (darken mids)\n",
    "# - unsharp_mask\n",
    "# - top_hat (morphological white tophat)\n",
    "# - black_hat (emphasize dark blobs)\n",
    "# - retinex_dog (difference-of-gaussians as a simple Retinex)\n",
    "# - canny_edges\n",
    "# - adaptive_thresh_overlay (binary mask overlay)\n",
    "#\n",
    "# It also exports a ZIP with all results for easy download.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def to_uint8(img):\n",
    "    img = np.clip(img, 0, 255)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "def ensure_3c(img):\n",
    "    if img.ndim == 2:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    return img\n",
    "\n",
    "def overlay_mask(base_bgr, mask, alpha=0.45, color=(0,255,255)):\n",
    "    base = base_bgr.copy()\n",
    "    overlay = base.copy()\n",
    "    overlay[mask>0] = color\n",
    "    return cv2.addWeighted(overlay, alpha, base, 1-alpha, 0)\n",
    "\n",
    "def put_label(img_bgr, text):\n",
    "    img = img_bgr.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    pad = 6\n",
    "    # semi-transparent label box\n",
    "    box_w = min(w, max(120, int(0.35*w)))\n",
    "    box_h = 28\n",
    "    overlay = img.copy()\n",
    "    cv2.rectangle(overlay, (0,0), (box_w, box_h), (0,0,0), -1)\n",
    "    img = cv2.addWeighted(overlay, 0.35, img, 0.65, 0)\n",
    "    cv2.putText(img, text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "# ---------- Enhancement Methods ----------\n",
    "def enhance_methods(bgr):\n",
    "    methods = {}\n",
    "    h, w = bgr.shape[:2]\n",
    "\n",
    "    # 1) Invert\n",
    "    inv = cv2.bitwise_not(bgr)\n",
    "    methods[\"invert\"] = inv\n",
    "\n",
    "    # 2) Red channel normalized\n",
    "    r = bgr[:,:,2].astype(np.float32)\n",
    "    r_norm = cv2.normalize(r, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    methods[\"red_channel_norm\"] = cv2.cvtColor(to_uint8(r_norm), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 3) R-G normalized (helps highlight dark insects on red boards)\n",
    "    g = bgr[:,:,1].astype(np.float32)\n",
    "    rg = r - g\n",
    "    rg_norm = cv2.normalize(rg, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    methods[\"red_minus_green_norm\"] = cv2.cvtColor(to_uint8(rg_norm), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 4) HSV V channel + CLAHE\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    v = hsv[:,:,2]\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    v_eq = clahe.apply(v)\n",
    "    hsv2 = hsv.copy()\n",
    "    hsv2[:,:,2] = v_eq\n",
    "    methods[\"hsv_v_clahe\"] = cv2.cvtColor(hsv2, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # 5) LAB L channel + CLAHE\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    l = lab[:,:,0]\n",
    "    l_eq = clahe.apply(l)\n",
    "    lab2 = lab.copy()\n",
    "    lab2[:,:,0] = l_eq\n",
    "    methods[\"lab_l_clahe\"] = cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # 6) Gamma correction (brighten mids)\n",
    "    def gamma_corr(img, gamma):\n",
    "        invGamma = 1.0 / gamma\n",
    "        table = np.array([(i / 255.0) ** invGamma * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "        return cv2.LUT(img, table)\n",
    "    methods[\"gamma_1p4\"] = gamma_corr(bgr, 1.4)\n",
    "    methods[\"gamma_0p7\"] = gamma_corr(bgr, 0.7)\n",
    "\n",
    "    # 7) Unsharp mask\n",
    "    blur = cv2.GaussianBlur(bgr, (0,0), sigmaX=1.2)\n",
    "    usm = cv2.addWeighted(bgr, 1.6, blur, -0.6, 0)\n",
    "    methods[\"unsharp_mask\"] = usm\n",
    "\n",
    "    # 8) Morphological Top-hat (white small bright spots)\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (31,31))\n",
    "    top_hat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)\n",
    "    methods[\"top_hat\"] = cv2.cvtColor(to_uint8(top_hat), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 9) Black-hat (small dark blobs on bright background)\n",
    "    black_hat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "    methods[\"black_hat\"] = cv2.cvtColor(to_uint8(black_hat), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 10) Retinex via Difference of Gaussians on grayscale, then normalize\n",
    "    g1 = cv2.GaussianBlur(gray, (0,0), 3)\n",
    "    g2 = cv2.GaussianBlur(gray, (0,0), 15)\n",
    "    dog = cv2.normalize((g1.astype(np.float32) - g2.astype(np.float32)), None, 0, 255, cv2.NORM_MINMAX)\n",
    "    methods[\"retinex_dog\"] = cv2.cvtColor(to_uint8(dog), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 11) Canny edges\n",
    "    v_med = np.median(gray)\n",
    "    lower = int(max(0, 0.66*v_med))\n",
    "    upper = int(min(255, 1.33*v_med))\n",
    "    edges = cv2.Canny(gray, lower, upper)\n",
    "    methods[\"canny_edges\"] = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 12) Adaptive threshold -> overlay\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY_INV, 35, 7)\n",
    "    overlay = overlay_mask(bgr, thr, alpha=0.45, color=(0,255,255))\n",
    "    methods[\"adaptive_thresh_overlay\"] = overlay\n",
    "\n",
    "    return methods\n",
    "\n",
    "# ---------- Process & Save ----------\n",
    "contact_sheets = []\n",
    "all_saved = []\n",
    "for path in in_paths:\n",
    "    bgr = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if bgr is None:\n",
    "        print(f\"Failed to read {path}\")\n",
    "        continue\n",
    "    name = os.path.splitext(os.path.basename(path))[0]\n",
    "    methods = enhance_methods(bgr)\n",
    "\n",
    "    # Save individual results\n",
    "    # indiv_dir = os.path.join(out_dir, name)\n",
    "    indiv_dir = out_dir\n",
    "    os.makedirs(indiv_dir, exist_ok=True)\n",
    "    for mname, img in methods.items():\n",
    "        labeled = put_label(ensure_3c(img), mname)\n",
    "        save_path = os.path.join(indiv_dir, f\"{name}_{mname}.png\")\n",
    "        # 只导出red_channel_norm结果\n",
    "        if mname == \"red_channel_norm\":\n",
    "            cv2.imwrite(save_path, labeled)\n",
    "        all_saved.append(save_path)\n",
    "\n",
    "    # Build contact sheet (3 cols x N rows)\n",
    "    keys = list(methods.keys())\n",
    "    cols = 3\n",
    "    thumb_w = 640\n",
    "    scale = thumb_w / bgr.shape[1]\n",
    "    thumb_h = int(bgr.shape[0] * scale)\n",
    "    thumbs = []\n",
    "    for k in keys:\n",
    "        im = ensure_3c(methods[k])\n",
    "        im_resized = cv2.resize(im, (thumb_w, thumb_h), interpolation=cv2.INTER_AREA)\n",
    "        im_resized = put_label(im_resized, k)\n",
    "        thumbs.append(im_resized)\n",
    "\n",
    "    rows = int(np.ceil(len(thumbs)/cols))\n",
    "    sheet_h = rows*thumb_h\n",
    "    sheet_w = cols*thumb_w\n",
    "    sheet = np.zeros((sheet_h, sheet_w, 3), dtype=np.uint8)\n",
    "    for idx, th in enumerate(thumbs):\n",
    "        r = idx // cols\n",
    "        c = idx % cols\n",
    "        sheet[r*thumb_h:(r+1)*thumb_h, c*thumb_w:(c+1)*thumb_w, :] = th\n",
    "\n",
    "    contact_path = os.path.join(out_dir, f\"{name}_contact_sheet.png\")\n",
    "    # cv2.imwrite(contact_path, sheet)\n",
    "    contact_sheets.append(contact_path)\n",
    "    all_saved.append(contact_path)\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Display contact sheets ----------\n",
    "# for cp in contact_sheets:\n",
    "#     img = cv2.cvtColor(cv2.imread(cp), cv2.COLOR_BGR2RGB)\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     plt.title(os.path.basename(cp))\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f6e77fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2627.593] global loadsave.cpp:268 findDecoder imread_('/workspace/models/SAHI/run_v9/tttt/elderfarm11.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m in_paths:\n\u001b[32m     64\u001b[39m     bgr = cv2.imread(p, cv2.IMREAD_COLOR)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     methods = \u001b[43mbrightness_inversions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbgr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     base = os.path.splitext(os.path.basename(p))[\u001b[32m0\u001b[39m]\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# sub = os.path.join(out_dir, base)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mbrightness_inversions\u001b[39m\u001b[34m(bgr)\u001b[39m\n\u001b[32m     24\u001b[39m methods = {}\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 1) RGB full invert (already had) for reference\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43madd_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minvert_rgb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbitwise_not\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbgr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 2) LAB L-channel invert (lightness inversion only)\u001b[39;00m\n\u001b[32m     29\u001b[39m lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36madd_method\u001b[39m\u001b[34m(methods, name, img)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_method\u001b[39m(methods, name, img):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     methods[name] = put_label(\u001b[43mensure_3c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m, name)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mensure_3c\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mensure_3c\u001b[39m(img):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m == \u001b[32m2\u001b[39m:\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "# Add additional \"brightness inversion\" variants focusing on lightness/value only,\n",
    "# plus R-only invert. Re-run for the same two images and save outputs alongside previous ones.\n",
    "\n",
    "import os, cv2, numpy as np, matplotlib.pyplot as plt, zipfile\n",
    "\n",
    "def ensure_3c(img):\n",
    "    if img.ndim == 2:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    return img\n",
    "\n",
    "def put_label(img_bgr, text):\n",
    "    img = img_bgr.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "    cv2.rectangle(overlay, (0,0), (int(0.38*w), 28), (0,0,0), -1)\n",
    "    img = cv2.addWeighted(overlay, 0.35, img, 0.65, 0)\n",
    "    cv2.putText(img, text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def add_method(methods, name, img):\n",
    "    methods[name] = put_label(ensure_3c(img), name)\n",
    "\n",
    "def brightness_inversions(bgr):\n",
    "    methods = {}\n",
    "    # 1) RGB full invert (already had) for reference\n",
    "    add_method(methods, \"invert_rgb\", cv2.bitwise_not(bgr))\n",
    "\n",
    "    # 2) LAB L-channel invert (lightness inversion only)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L, A, B = cv2.split(lab)\n",
    "    L_inv = 255 - L\n",
    "    lab_inv = cv2.merge([L_inv, A, B])\n",
    "    add_method(methods, \"invert_L_in_LAB\", cv2.cvtColor(lab_inv, cv2.COLOR_LAB2BGR))\n",
    "\n",
    "    # 3) HSV V-channel invert (value inversion only)\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "    V_inv = 255 - V\n",
    "    hsv_inv = cv2.merge([H, S, V_inv])\n",
    "    add_method(methods, \"invert_V_in_HSV\", cv2.cvtColor(hsv_inv, cv2.COLOR_HSV2BGR))\n",
    "\n",
    "    # 4) Grayscale invert (luminance only)\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray_inv = 255 - gray\n",
    "    add_method(methods, \"invert_grayscale\", cv2.cvtColor(gray_inv, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "    # 5) R-channel only inversion (red board polarity flip)\n",
    "    b, g, r = cv2.split(bgr)\n",
    "    r_inv = 255 - r\n",
    "    add_method(methods, \"invert_R_only\", cv2.merge([b, g, r_inv]))\n",
    "\n",
    "    # 6) R-channel invert + slight unsharp (often closest to “polarity flip” look)\n",
    "    r_only_inv = cv2.merge([b, g, r_inv])\n",
    "    blur = cv2.GaussianBlur(r_only_inv, (0,0), 1.2)\n",
    "    usm = cv2.addWeighted(r_only_inv, 1.6, blur, -0.6, 0)\n",
    "    add_method(methods, \"invert_R_only_usm\", usm)\n",
    "\n",
    "    return methods\n",
    "\n",
    "# Process\n",
    "sheet_paths = []\n",
    "saved = []\n",
    "for p in in_paths:\n",
    "    bgr = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "    methods = brightness_inversions(bgr)\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(p))[0]\n",
    "    # sub = os.path.join(out_dir, base)\n",
    "    sub = out_dir\n",
    "    os.makedirs(sub, exist_ok=True)\n",
    "    # save individuals and compose contact sheet\n",
    "    thumbs = []\n",
    "    cols = 3\n",
    "    tw = 640\n",
    "    scale = tw / bgr.shape[1]\n",
    "    th = int(bgr.shape[0]*scale)\n",
    "\n",
    "    for name, img in methods.items():\n",
    "        save_path = os.path.join(sub, f\"{base}_{name}.png\")\n",
    "        # 只导出invert_L_in_LAB，invert_V_in_HSV结果\n",
    "        if name in [\"invert_L_in_LAB\", \"invert_V_in_HSV\"]:\n",
    "            cv2.imwrite(save_path, img)\n",
    "        saved.append(save_path)\n",
    "        th_img = cv2.resize(img, (tw, th), interpolation=cv2.INTER_AREA)\n",
    "        thumbs.append(th_img)\n",
    "\n",
    "    rows = int(np.ceil(len(thumbs)/cols))\n",
    "    sheet = np.zeros((rows*th, cols*tw, 3), dtype=np.uint8)\n",
    "    for i, timg in enumerate(thumbs):\n",
    "        r = i//cols; c = i%cols\n",
    "        sheet[r*th:(r+1)*th, c*tw:(c+1)*tw] = timg\n",
    "    sheet_path = os.path.join(out_dir, f\"{base}_brightness_inversions_contact.png\")\n",
    "    # cv2.imwrite(sheet_path, sheet)\n",
    "    sheet_paths.append(sheet_path)\n",
    "    saved.append(sheet_path)\n",
    "\n",
    "# # Display sheets\n",
    "# for cp in sheet_paths:\n",
    "#     img = cv2.cvtColor(cv2.imread(cp), cv2.COLOR_BGR2RGB)\n",
    "#     plt.figure(figsize=(12,8)); plt.imshow(img); plt.axis('off'); plt.title(os.path.basename(cp))\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
