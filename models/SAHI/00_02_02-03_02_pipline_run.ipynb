{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51bf90cd",
   "metadata": {},
   "source": [
    "# æŸ¥çœ‹æ ¹ç›®å½•ä¸‹éœ€è¦è¿è¡Œçš„æ–‡ä»¶å¤¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a2b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰¾åˆ°ä»¥ä¸‹ _data æ•°æ®é›†ï¼š\n",
      "[0] /workspace/models/SAHI/run_v7/ms1_0726-0809_11/raw_data\n",
      "[1] /workspace/models/SAHI/run_v7/air1_0729-0813_5/raw_data\n",
      "[2] /workspace/models/SAHI/run_v7/air1_0826-0909_21_no/raw_data\n",
      "[3] /workspace/models/SAHI/run_v7/air1_0909-0923_02_wait/raw_data\n",
      "[4] /workspace/models/SAHI/run_v7/air1_0923-1007_01_wait/raw_data\n",
      "[5] /workspace/models/SAHI/run_v7/air2_0729-0813_04/raw_data\n",
      "[6] /workspace/models/SAHI/run_v7/air2_0826-0909_25_no/raw_data\n",
      "[7] /workspace/models/SAHI/run_v7/air2_0923-1007_02_wait/raw_data\n",
      "[8] /workspace/models/SAHI/run_v7/jeff_0613-0624_04_ok/raw_data\n",
      "[9] /workspace/models/SAHI/run_v7/jeff_0624-0702_01_ok/raw_data\n",
      "[10] /workspace/models/SAHI/run_v7/jeff_0730-0813_01/raw_data\n",
      "[11] /workspace/models/SAHI/run_v7/lloyd_0603-0618_31/raw_data\n",
      "[12] /workspace/models/SAHI/run_v7/lloyd_0715-0729_04/raw_data\n",
      "[13] /workspace/models/SAHI/run_v7/lloyd_0826-0909_04/raw_data\n",
      "[14] /workspace/models/SAHI/run_v7/ms1_0605-0621_40/raw_data\n",
      "[15] /workspace/models/SAHI/run_v7/ms1_0621-0710_04/raw_data\n",
      "[16] /workspace/models/SAHI/run_v7/ms1_0710-0726_36/raw_data\n",
      "[17] /workspace/models/SAHI/run_v7/ms1_0809-0823_34/raw_data\n",
      "[18] /workspace/models/SAHI/run_v7/ms1_0823-0906_25_no/raw_data\n",
      "[19] /workspace/models/SAHI/run_v7/ms1_0906-0920_10_no/raw_data\n",
      "[20] /workspace/models/SAHI/run_v7/ms1_0920-1004_04_wait/raw_data\n",
      "[21] /workspace/models/SAHI/run_v7/ms1_1004-1020_21_wait/raw_data\n",
      "[22] /workspace/models/SAHI/run_v7/ms2_0601-0605_01_wait/raw_data\n",
      "[23] /workspace/models/SAHI/run_v7/ms2_0621-0710_01/raw_data\n",
      "[24] /workspace/models/SAHI/run_v7/ms2_0726-0809_13/raw_data\n",
      "[25] /workspace/models/SAHI/run_v7/ms2_0809-0823_10/raw_data\n",
      "[26] /workspace/models/SAHI/run_v7/ms2_1004-1020_02_wait/raw_data\n",
      "[27] /workspace/models/SAHI/run_v7/southfarm1_0701-0715_04/raw_data\n",
      "[28] /workspace/models/SAHI/run_v7/southfarm1_0715-0813_01_wait/raw_data\n",
      "[29] /workspace/models/SAHI/run_v7/southfarm1_0924-1007_01_no/raw_data\n",
      "[30] /workspace/models/SAHI/run_v7/southfarm2_1007-1022_61_wait/raw_data\n",
      "[31] /workspace/models/SAHI/run_v7/sw1_0605-0613_07_ok/raw_data\n",
      "[32] /workspace/models/SAHI/run_v7/sw1_0627-0711_02/raw_data\n",
      "[33] /workspace/models/SAHI/run_v7/sw1_0711-0725_03/raw_data\n",
      "[34] /workspace/models/SAHI/run_v7/sw1_0808-0823_01/raw_data\n",
      "[35] /workspace/models/SAHI/run_v7/sw1_0927-1011_01_wait/raw_data\n",
      "[36] /workspace/models/SAHI/run_v7/sw2_0725-0808_02/raw_data\n",
      "[37] /workspace/models/SAHI/run_v7/sw2_0808-0823_04/raw_data\n",
      "å°†å¤„ç†ä»¥ä¸‹ _data ç›®å½•ï¼š\n",
      "- 1. /workspace/models/SAHI/run_v7/ms1_0726-0809_11/raw_data\n",
      "- 2. /workspace/models/SAHI/run_v7/air1_0729-0813_5/raw_data\n",
      "- 3. /workspace/models/SAHI/run_v7/air1_0826-0909_21_no/raw_data\n",
      "- 4. /workspace/models/SAHI/run_v7/air1_0909-0923_02_wait/raw_data\n",
      "- 5. /workspace/models/SAHI/run_v7/air1_0923-1007_01_wait/raw_data\n",
      "- 6. /workspace/models/SAHI/run_v7/air2_0729-0813_04/raw_data\n",
      "- 7. /workspace/models/SAHI/run_v7/air2_0826-0909_25_no/raw_data\n",
      "- 8. /workspace/models/SAHI/run_v7/air2_0923-1007_02_wait/raw_data\n",
      "- 9. /workspace/models/SAHI/run_v7/jeff_0613-0624_04_ok/raw_data\n",
      "- 10. /workspace/models/SAHI/run_v7/jeff_0624-0702_01_ok/raw_data\n",
      "- 11. /workspace/models/SAHI/run_v7/jeff_0730-0813_01/raw_data\n",
      "- 12. /workspace/models/SAHI/run_v7/lloyd_0603-0618_31/raw_data\n",
      "- 13. /workspace/models/SAHI/run_v7/lloyd_0715-0729_04/raw_data\n",
      "- 14. /workspace/models/SAHI/run_v7/lloyd_0826-0909_04/raw_data\n",
      "- 15. /workspace/models/SAHI/run_v7/ms1_0605-0621_40/raw_data\n",
      "- 16. /workspace/models/SAHI/run_v7/ms1_0621-0710_04/raw_data\n",
      "- 17. /workspace/models/SAHI/run_v7/ms1_0710-0726_36/raw_data\n",
      "- 18. /workspace/models/SAHI/run_v7/ms1_0809-0823_34/raw_data\n",
      "- 19. /workspace/models/SAHI/run_v7/ms1_0823-0906_25_no/raw_data\n",
      "- 20. /workspace/models/SAHI/run_v7/ms1_0906-0920_10_no/raw_data\n",
      "- 21. /workspace/models/SAHI/run_v7/ms1_0920-1004_04_wait/raw_data\n",
      "- 22. /workspace/models/SAHI/run_v7/ms1_1004-1020_21_wait/raw_data\n",
      "- 23. /workspace/models/SAHI/run_v7/ms2_0601-0605_01_wait/raw_data\n",
      "- 24. /workspace/models/SAHI/run_v7/ms2_0621-0710_01/raw_data\n",
      "- 25. /workspace/models/SAHI/run_v7/ms2_0726-0809_13/raw_data\n",
      "- 26. /workspace/models/SAHI/run_v7/ms2_0809-0823_10/raw_data\n",
      "- 27. /workspace/models/SAHI/run_v7/ms2_1004-1020_02_wait/raw_data\n",
      "- 28. /workspace/models/SAHI/run_v7/southfarm1_0701-0715_04/raw_data\n",
      "- 29. /workspace/models/SAHI/run_v7/southfarm1_0715-0813_01_wait/raw_data\n",
      "- 30. /workspace/models/SAHI/run_v7/southfarm1_0924-1007_01_no/raw_data\n",
      "- 31. /workspace/models/SAHI/run_v7/southfarm2_1007-1022_61_wait/raw_data\n",
      "- 32. /workspace/models/SAHI/run_v7/sw1_0605-0613_07_ok/raw_data\n",
      "- 33. /workspace/models/SAHI/run_v7/sw1_0627-0711_02/raw_data\n",
      "- 34. /workspace/models/SAHI/run_v7/sw1_0711-0725_03/raw_data\n",
      "- 35. /workspace/models/SAHI/run_v7/sw1_0808-0823_01/raw_data\n",
      "- 36. /workspace/models/SAHI/run_v7/sw1_0927-1011_01_wait/raw_data\n",
      "- 37. /workspace/models/SAHI/run_v7/sw2_0725-0808_02/raw_data\n",
      "- 38. /workspace/models/SAHI/run_v7/sw2_0808-0823_04/raw_data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # === 1) ç»™å®šä¸€ä¸ªæ ¹ç›®å½• ===\n",
    "    root_dir = Path(\"/workspace/models/SAHI/run_v7\")\n",
    "    # end_with = \"_sliced\"\n",
    "    end_with = \"_data\"\n",
    "\n",
    "    # === 2) éå†æ‰€æœ‰å­ç›®å½• ===\n",
    "    sub_dirs = list(root_dir.glob(\"**/*\" + end_with))\n",
    "\n",
    "\n",
    "    if not sub_dirs:\n",
    "        print(f\"æ²¡æœ‰æ‰¾åˆ° *{end_with} ç›®å½•\")\n",
    "        exit(0)\n",
    "\n",
    "    print(f\"æ‰¾åˆ°ä»¥ä¸‹ {end_with} æ•°æ®é›†ï¼š\")\n",
    "    for i, d in enumerate(sub_dirs):\n",
    "        print(f\"[{i}] {d}\")\n",
    "\n",
    "    # === 3) è®©ä½ é€‰æ‹©è¦è·‘çš„ç›®å½• ===\n",
    "    idx_str = input(\"è¯·è¾“å…¥è¦å¤„ç†çš„ç¼–å· (å¤šä¸ªç”¨é€—å·åˆ†éš”, å›è½¦é»˜è®¤å…¨é€‰): \").strip()\n",
    "    if idx_str:\n",
    "        indices = [int(x) for x in idx_str.split(\",\")]\n",
    "        chosen_dirs = [sub_dirs[i] for i in indices]\n",
    "    else:\n",
    "        chosen_dirs = sub_dirs\n",
    "    \n",
    "    print(f\"å°†å¤„ç†ä»¥ä¸‹ {end_with} ç›®å½•ï¼š\")\n",
    "    for i, d in enumerate(chosen_dirs):\n",
    "        print(f\"- {i+1}. {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad3179",
   "metadata": {},
   "source": [
    "# 0202\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os, gc\n",
    "import orjson as jsonlib\n",
    "import torch\n",
    "\n",
    "model = YOLO(\"/workspace/models/best_model/yolo11n-seg-best.pt\")\n",
    "\n",
    "# â€”â€” æ¨èçš„ç»Ÿä¸€å‚æ•°ï¼ˆæ›´çœæ˜¾å­˜ï¼‰ â€”â€”\n",
    "COMMON_KW = dict(\n",
    "    imgsz=640,              # æ¯” 640 æ›´çœæ˜¾å­˜ï¼›çœ‹ç²¾åº¦å†è°ƒ\n",
    "    conf=0.25,\n",
    "    iou=0.45,\n",
    "    device=0,               # '0' or 0 éƒ½è¡Œ\n",
    "    # stream=True,            # æµå¼\n",
    "    batch=3,                # 2~4 ä¹‹é—´æ‰¾å¹³è¡¡\n",
    "    retina_masks=False,     # çœæ˜¾å­˜\n",
    "    workers=2,              # é™ä½ DataLoader çº¿ç¨‹\n",
    "    verbose=False,\n",
    "    save=False,             # ä¸è¦é¢å¤–ä¿å­˜å¯è§†åŒ–\n",
    ")\n",
    "\n",
    "_dumps = lambda obj: jsonlib.dumps(obj, option=jsonlib.OPT_INDENT_2 | jsonlib.OPT_NON_STR_KEYS)\n",
    "_loads = jsonlib.loads\n",
    "\n",
    "for d in chosen_dirs:\n",
    "    print(f\"\\n=== å¤„ç†ç›®å½•: {d} ===\")\n",
    "    src_dir = Path(str(d) + \"_sliced\")\n",
    "    if not src_dir.exists() or not any(src_dir.iterdir()):\n",
    "        print(f\"è·³è¿‡ç©ºç›®å½•: {src_dir}\")\n",
    "        continue\n",
    "\n",
    "    # å¯é€‰ï¼šæŠŠç›®å½•åˆ†æ‰¹ï¼ˆåˆ†ç‰‡ï¼‰å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§æŒ‚å¤ªå¤šæ–‡ä»¶åˆ° DataLoader\n",
    "    all_imgs = [p for p in src_dir.glob(\"*.jpg\")] + [p for p in src_dir.glob(\"*.png\")]\n",
    "    if not all_imgs:\n",
    "        print(f\"æ— å›¾ç‰‡: {src_dir}\")\n",
    "        continue\n",
    "\n",
    "    # åˆ†ç‰‡å¤§å°ï¼ˆæŒ‰æ˜¾å­˜è°ƒæ•´ï¼›å‡ åƒå¼ å›¾å°±åˆ†ç‰‡ï¼‰\n",
    "    CHUNK = 300\n",
    "    for si in range(0, len(all_imgs), CHUNK):\n",
    "        chunk = all_imgs[si:si+CHUNK]\n",
    "        print(f\" -> åˆ†ç‰‡ {si}-{si+len(chunk)-1} / {len(all_imgs)}\")\n",
    "\n",
    "        # ç”¨æµå¼é¢„æµ‹ + å° batch\n",
    "        results_gen = model.predict(chunk, **COMMON_KW)\n",
    "\n",
    "        # é€æ¡ç»“æœç«‹åˆ»è½ç›˜å¹¶é‡Šæ”¾\n",
    "        for i, result in enumerate(results_gen, 1):\n",
    "            try:\n",
    "                det_list = _loads(result.to_json())\n",
    "\n",
    "                h, w = map(int, result.orig_shape[:2])\n",
    "                img_name = os.path.basename(getattr(result, \"path\", \"\")) or f\"image_{i}.png\"\n",
    "\n",
    "                shapes = []\n",
    "                for det in det_list:\n",
    "                    seg = det.get(\"segments\", {})\n",
    "                    xs, ys = seg.get(\"x\", []), seg.get(\"y\", [])\n",
    "                    if not xs or not ys:\n",
    "                        continue\n",
    "                    points = [[float(x), float(y)] for x, y in zip(xs, ys)]\n",
    "                    shapes.append({\n",
    "                        \"label\": det.get(\"name\", \"\"),\n",
    "                        \"score\": float(det.get(\"confidence\", 0.0)),\n",
    "                        \"points\": points,\n",
    "                        \"shape_type\": \"polygon\",\n",
    "                    })\n",
    "\n",
    "                labelme_obj = {\n",
    "                    \"shapes\": shapes,\n",
    "                    \"imagePath\": img_name,\n",
    "                    \"imageHeight\": h,\n",
    "                    \"imageWidth\": w,\n",
    "                }\n",
    "\n",
    "                out_path = src_dir / f\"{Path(img_name).stem}.json\"\n",
    "                out_path.write_bytes(_dumps(labelme_obj))\n",
    "\n",
    "            finally:\n",
    "                # åŠæ—¶é‡Šæ”¾ GPU/CPU å†…å­˜\n",
    "                del result\n",
    "                if i % 64 == 0:  # æ¯ 64 å¼ æ¸…ä¸€æ¬¡ç¼“å­˜ï¼ˆå¯é…Œæƒ…è°ƒæ•´ï¼‰\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "        # åˆ†ç‰‡ç»“æŸå†æ¸…ä¸€æ¬¡\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"âœ… Done. Saved to: {src_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79cea1c",
   "metadata": {},
   "source": [
    "# 0203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import uuid\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Optional, Iterable, List, Dict, Any, Tuple\n",
    "\n",
    "import orjson\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# ============== JSON å°è£…ï¼ˆorjsonï¼‰ ==============\n",
    "def json_load(path: str):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return orjson.loads(f.read())\n",
    "\n",
    "def json_dump(obj, path: str):\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(orjson.dumps(obj, option=orjson.OPT_INDENT_2))\n",
    "\n",
    "\n",
    "# ============== shapelyï¼ˆå¯é€‰ï¼‰ ==============\n",
    "try:\n",
    "    from shapely.geometry import Polygon\n",
    "    from shapely.ops import unary_union\n",
    "    _HAVE_SHAPELY = True\n",
    "except Exception:\n",
    "    _HAVE_SHAPELY = False\n",
    "\n",
    "\n",
    "# ============== å·¥å…·ï¼šåŸå›¾ç´¢å¼•ä¸ç»˜åˆ¶ ==============\n",
    "def _build_image_index(original_image_dir: str) -> Dict[str, str]:\n",
    "    \"\"\"ä¸€æ¬¡æ€§å»ºç«‹ åŸå›¾stem -> ç»å¯¹è·¯å¾„ çš„ç´¢å¼•ï¼Œé¿å…æ¯å¼ å›¾éƒ½ listdirã€‚\"\"\"\n",
    "    idx: Dict[str, str] = {}\n",
    "    for p in Path(original_image_dir).glob(\"*.jpg\"):\n",
    "        idx[p.stem] = str(p)\n",
    "    return idx\n",
    "\n",
    "def _draw_one_image_cv2(args: Tuple[str, List[Dict[str, Any]], str, str, bool, int]) -> bool:\n",
    "    \"\"\"\n",
    "    å­è¿›ç¨‹ï¼šOpenCV ç»˜åˆ¶å¤šè¾¹å½¢ä¸å¯é€‰æ–‡å­—ï¼Œå¹¶ä¿å­˜ JPEG\n",
    "    args = (image_name, annotations, image_path, out_dir, draw_text, jpeg_quality)\n",
    "    \"\"\"\n",
    "    image_name, annotations, image_path, out_dir, draw_text, jpeg_quality = args\n",
    "    img = cv2.imread(image_path)  # BGR\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    for ann in annotations:\n",
    "        pts = np.asarray(ann[\"points\"], dtype=np.int32).reshape(-1, 1, 2)\n",
    "        # å¤šè¾¹å½¢ï¼ˆé»„è‰²BGR=(0,255,255)ï¼‰\n",
    "        cv2.polylines(img, [pts], isClosed=True, thickness=1, color=(0, 255, 255))\n",
    "\n",
    "        if draw_text:\n",
    "            label = ann.get(\"label\", \"\")\n",
    "            score = float(ann.get(\"score\", 0.0))\n",
    "            x0, y0 = int(ann[\"points\"][0][0]) + 12, int(ann[\"points\"][0][1]) + 12\n",
    "            txt = f\"{label} {score:.3f}\"\n",
    "            # é»‘åº• + é»„è‰²å­—\n",
    "            cv2.putText(img, txt, (x0, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(img, txt, (x0, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    out_path = os.path.join(out_dir, f\"{image_name}_vis.jpg\")\n",
    "    cv2.imwrite(out_path, img, [int(cv2.IMWRITE_JPEG_QUALITY), int(jpeg_quality)])\n",
    "    return True\n",
    "\n",
    "\n",
    "# ============== è§£æåˆ‡ç‰‡æ–‡ä»¶å ==============\n",
    "def parse_filename(filename: str):\n",
    "    \"\"\"è§£æåˆ‡ç‰‡æ–‡ä»¶åè·å–åŸå›¾åå’Œåç§»ï¼ˆ..._x1_y1_x2_y2ï¼‰\"\"\"\n",
    "    parts = Path(filename).stem.split(\"_\")\n",
    "    name = \"_\".join(parts[:-4])\n",
    "    x1, y1, x2, y2 = map(int, parts[-4:])\n",
    "    return name, x1, y1\n",
    "\n",
    "\n",
    "# ============== åˆå¹¶æ‰€æœ‰åˆ‡ç‰‡æ ‡æ³¨ ==============\n",
    "def merge_annotations(sliced_label_dir: str, output_json_path: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    merged_annotations: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n",
    "    json_files = list(Path(sliced_label_dir).rglob(\"*.json\"))\n",
    "\n",
    "    for json_file in tqdm(json_files, desc=\"Merging JSON\", unit=\"file\"):\n",
    "        data = json_load(str(json_file))\n",
    "        image_path = data[\"imagePath\"]\n",
    "        original_name, offset_x, offset_y = parse_filename(image_path)\n",
    "        for shape in data.get(\"shapes\", []):\n",
    "            points = shape[\"points\"]\n",
    "            label = shape.get(\"label\", \"\")\n",
    "            new_points = [[x + offset_x, y + offset_y] for x, y in points]\n",
    "            merged_annotations[original_name].append({\n",
    "                \"uuid\": str(uuid.uuid4()),\n",
    "                \"original_name\": original_name,\n",
    "                \"label\": label,\n",
    "                \"points\": new_points,\n",
    "                \"offset_x\": offset_x,\n",
    "                \"offset_y\": offset_y,\n",
    "                \"score\": float(shape.get(\"score\", 0.0)),\n",
    "            })\n",
    "\n",
    "    json_dump(merged_annotations, output_json_path)\n",
    "    print(f\"âœ… åˆå¹¶å®Œæˆï¼Œå…±å¤„ç† {len(merged_annotations)} å¼ åŸå›¾\")\n",
    "    print(f\"âœ”ï¸ åˆå¹¶æ ‡æ³¨å·²ä¿å­˜åˆ° {output_json_path}\")\n",
    "    return merged_annotations\n",
    "\n",
    "\n",
    "# ============== åå¤„ç†å»é‡ï¼ˆNMS/GREEDYNMM/NMM/LSNMSï¼‰ ==============\n",
    "def remove_duplicate_annotations(\n",
    "    merged_annotations: Dict[str, List[Dict[str, Any]]],\n",
    "    output_json_path: str,\n",
    "    postprocess_type: str = \"GREEDYNMM\",           # 'NMM' | 'GREEDYNMM' | 'LSNMS' | 'NMS'\n",
    "    postprocess_match_metric: str = \"IOS\",         # 'IOU' | 'IOS'\n",
    "    postprocess_match_threshold: float = 0.5,\n",
    "    postprocess_class_agnostic: bool = False,\n",
    "    center_thresh: Optional[float] = 20.0,\n",
    "    keep_mode: str = \"REP\"                         # 'REP' or 'UNION_POLY'\n",
    ") -> Dict[str, List[Dict[str, Any]]]:\n",
    "\n",
    "    def polygon_to_bbox(points: Iterable[Iterable[float]]) -> List[float]:\n",
    "        xs, ys = zip(*points)\n",
    "        return [min(xs), min(ys), max(xs), max(ys)]\n",
    "\n",
    "    def bbox_area(b):\n",
    "        w = b[2] - b[0]; h = b[3] - b[1]\n",
    "        return (w if w > 0 else 0) * (h if h > 0 else 0)\n",
    "\n",
    "    def bbox_iou(A, B):\n",
    "        xA = max(A[0], B[0]); yA = max(A[1], B[1])\n",
    "        xB = min(A[2], B[2]); yB = min(A[3], B[3])\n",
    "        inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "        if inter <= 0: return 0.0\n",
    "        u = bbox_area(A) + bbox_area(B) - inter\n",
    "        return inter / u if u > 0 else 0.0\n",
    "\n",
    "    def bbox_ios(A, B):\n",
    "        xA = max(A[0], B[0]); yA = max(A[1], B[1])\n",
    "        xB = min(A[2], B[2]); yB = min(A[3], B[3])\n",
    "        inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "        if inter <= 0: return 0.0\n",
    "        smaller = min(bbox_area(A), bbox_area(B))\n",
    "        return inter / smaller if smaller > 0 else 0.0\n",
    "\n",
    "    def center_distance(A, B):\n",
    "        cxA = (A[0] + A[2]) * 0.5; cyA = (A[1] + A[3]) * 0.5\n",
    "        cxB = (B[0] + B[2]) * 0.5; cyB = (B[1] + B[3]) * 0.5\n",
    "        return math.hypot(cxA - cxB, cyA - cyB)\n",
    "\n",
    "    match_metric = bbox_iou if postprocess_match_metric.upper() == \"IOU\" else bbox_ios\n",
    "\n",
    "    def same_group(ann_i: Dict, ann_j: Dict) -> bool:\n",
    "        if (not postprocess_class_agnostic) and (ann_i[\"label\"] != ann_j[\"label\"]):\n",
    "            return False\n",
    "        bi = polygon_to_bbox(ann_i[\"points\"])\n",
    "        bj = polygon_to_bbox(ann_j[\"points\"])\n",
    "        if (center_thresh is not None) and center_distance(bi, bj) > center_thresh:\n",
    "            return False\n",
    "        return match_metric(bi, bj) >= postprocess_match_threshold\n",
    "\n",
    "    def safe_score(a: Dict) -> float:\n",
    "        try:\n",
    "            return float(a.get(\"score\", 0.0))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    def choose_rep_polygon_by_score(grp: List[Dict]) -> Dict:\n",
    "        best = None\n",
    "        best_key = (-1e9, -1e9)  # (score, overlap_sum)\n",
    "        for i, ai in enumerate(grp):\n",
    "            bi = polygon_to_bbox(ai[\"points\"])\n",
    "            overlap_sum = 0.0\n",
    "            for j, aj in enumerate(grp):\n",
    "                if i == j: continue\n",
    "                overlap_sum += match_metric(bi, polygon_to_bbox(aj[\"points\"]))\n",
    "            key = (safe_score(ai), overlap_sum)\n",
    "            if key > best_key:\n",
    "                best_key = key; best = ai\n",
    "        rep = dict(best)\n",
    "        rep[\"uuid\"] = str(uuid.uuid4())\n",
    "        return rep\n",
    "\n",
    "    def union_polygon(grp: List[Dict]) -> Dict:\n",
    "        if not _HAVE_SHAPELY:\n",
    "            return choose_rep_polygon_by_score(grp)\n",
    "        polys = []\n",
    "        for a in grp:\n",
    "            pts = a[\"points\"]\n",
    "            if len(pts) >= 3:\n",
    "                try:\n",
    "                    polys.append(Polygon(pts))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        if not polys:\n",
    "            return choose_rep_polygon_by_score(grp)\n",
    "        merged = unary_union(polys)\n",
    "        if merged.geom_type == \"MultiPolygon\":\n",
    "            merged = max(list(merged.geoms), key=lambda p: p.area)\n",
    "        xys = list(merged.exterior.coords)[:-1]\n",
    "        base = dict(grp[0])\n",
    "        base[\"uuid\"] = str(uuid.uuid4())\n",
    "        base[\"points\"] = [[float(x), float(y)] for (x, y) in xys] or grp[0][\"points\"]\n",
    "        base[\"score\"] = max(safe_score(a) for a in grp)\n",
    "        return base\n",
    "\n",
    "    def merge_group(grp: List[Dict]) -> Dict:\n",
    "        return union_polygon(grp) if keep_mode.upper() == \"UNION_POLY\" else choose_rep_polygon_by_score(grp)\n",
    "\n",
    "    def nms_by_score(anns: List[Dict]) -> List[Dict]:\n",
    "        anns_sorted = sorted(anns, key=lambda a: safe_score(a), reverse=True)\n",
    "        keep: List[Dict] = []\n",
    "        for a in anns_sorted:\n",
    "            suppress = False\n",
    "            ba = None\n",
    "            for b in keep:\n",
    "                if (not postprocess_class_agnostic) and a[\"label\"] != b[\"label\"]:\n",
    "                    continue\n",
    "                if ba is None:\n",
    "                    ba = [*map(min, zip(*a[\"points\"]))]  # lazy bboxè®¡ç®—ï¼ˆä½†ä¸‹é¢æ›´å®‰å…¨ç®—ä¸€æ¬¡ï¼‰\n",
    "                    ba = polygon_to_bbox(a[\"points\"])\n",
    "                bb = polygon_to_bbox(b[\"points\"])\n",
    "                if (center_thresh is None or center_distance(ba, bb) <= center_thresh) and \\\n",
    "                   match_metric(ba, bb) >= postprocess_match_threshold:\n",
    "                    suppress = True; break\n",
    "            if not suppress:\n",
    "                keep.append(a)\n",
    "        out = []\n",
    "        for k in keep:\n",
    "            kk = dict(k); kk[\"uuid\"] = str(uuid.uuid4())\n",
    "            out.append(kk)\n",
    "        return out\n",
    "\n",
    "    def greedy_group_by_score(anns: List[Dict]) -> List[List[Dict]]:\n",
    "        used = [False] * len(anns)\n",
    "        order = sorted(range(len(anns)), key=lambda i: safe_score(anns[i]), reverse=True)\n",
    "        groups: List[List[Dict]] = []\n",
    "        for idx in order:\n",
    "            if used[idx]: continue\n",
    "            seed = anns[idx]\n",
    "            grp = [seed]; used[idx] = True\n",
    "            changed = True\n",
    "            while changed:\n",
    "                changed = False\n",
    "                for j, aj in enumerate(anns):\n",
    "                    if used[j]: continue\n",
    "                    if any(same_group(aj, g) for g in grp):\n",
    "                        grp.append(aj); used[j] = True; changed = True\n",
    "            groups.append(grp)\n",
    "        return groups\n",
    "\n",
    "    def pairwise_group(anns: List[Dict]) -> List[List[Dict]]:\n",
    "        used = [False] * len(anns)\n",
    "        groups: List[List[Dict]] = []\n",
    "        order = sorted(range(len(anns)), key=lambda i: safe_score(anns[i]), reverse=True)\n",
    "        for idx in order:\n",
    "            if used[idx]: continue\n",
    "            seed = anns[idx]\n",
    "            grp = [seed]; used[idx] = True\n",
    "            for j in order:\n",
    "                if used[j]: continue\n",
    "                if same_group(seed, anns[j]):\n",
    "                    grp.append(anns[j]); used[j] = True\n",
    "            groups.append(grp)\n",
    "        return groups\n",
    "\n",
    "    def lsnms_like(anns: List[Dict]) -> List[Dict]:\n",
    "        anns_sorted = sorted(anns, key=lambda a: safe_score(a), reverse=True)\n",
    "        kept_reps: List[Dict] = []\n",
    "        suppressed = [False] * len(anns_sorted)\n",
    "        for i, ai in enumerate(anns_sorted):\n",
    "            if suppressed[i]: continue\n",
    "            group = [ai]; suppressed[i] = True\n",
    "            bai = polygon_to_bbox(ai[\"points\"])\n",
    "            for j in range(i + 1, len(anns_sorted)):\n",
    "                if suppressed[j]: continue\n",
    "                aj = anns_sorted[j]\n",
    "                if (not postprocess_class_agnostic) and (ai[\"label\"] != aj[\"label\"]):\n",
    "                    continue\n",
    "                baj = polygon_to_bbox(aj[\"points\"])\n",
    "                if (center_thresh is None or center_distance(bai, baj) <= center_thresh) and \\\n",
    "                   match_metric(bai, baj) >= postprocess_match_threshold:\n",
    "                    group.append(aj); suppressed[j] = True\n",
    "            kept_reps.append(merge_group(group))\n",
    "        return kept_reps\n",
    "\n",
    "    cleaned_annotations: Dict[str, List[Dict]] = {}\n",
    "    total_before = sum(len(v) for v in merged_annotations.values())\n",
    "    total_after = 0\n",
    "\n",
    "    for image_name, ann_list in tqdm(merged_annotations.items(), desc=\"Postprocessing\", unit=\"image\"):\n",
    "        if not postprocess_class_agnostic:\n",
    "            buckets = defaultdict(list)\n",
    "            for a in ann_list:\n",
    "                buckets[a[\"label\"]].append(a)\n",
    "            out_list: List[Dict] = []\n",
    "            for _, bucket in buckets.items():\n",
    "                t = postprocess_type.upper()\n",
    "                if t == \"NMS\":\n",
    "                    out_list.extend(nms_by_score(bucket))\n",
    "                elif t == \"NMM\":\n",
    "                    out_list.extend(merge_group(g) for g in pairwise_group(bucket))\n",
    "                elif t == \"LSNMS\":\n",
    "                    out_list.extend(lsnms_like(bucket))\n",
    "                else:  # GREEDYNMM\n",
    "                    out_list.extend(merge_group(g) for g in greedy_group_by_score(bucket))\n",
    "        else:\n",
    "            t = postprocess_type.upper()\n",
    "            if t == \"NMS\":\n",
    "                out_list = nms_by_score(ann_list)\n",
    "            elif t == \"NMM\":\n",
    "                out_list = [merge_group(g) for g in pairwise_group(ann_list)]\n",
    "            elif t == \"LSNMS\":\n",
    "                out_list = lsnms_like(ann_list)\n",
    "            else:\n",
    "                out_list = [merge_group(g) for g in greedy_group_by_score(ann_list)]\n",
    "\n",
    "        cleaned_annotations[image_name] = out_list\n",
    "        total_after += len(out_list)\n",
    "\n",
    "    json_dump(cleaned_annotations, output_json_path)\n",
    "\n",
    "    print(f\"ğŸ” åå¤„ç†å®Œæˆï¼ˆ{postprocess_type}, metric={postprocess_match_metric}, thr={postprocess_match_threshold}, class_agnostic={postprocess_class_agnostic}, keep={keep_mode}ï¼‰\")\n",
    "    print(f\"    ç›®æ ‡æ•°ï¼š{total_before} â†’ {total_after}\")\n",
    "    if keep_mode.upper() == \"UNION_POLY\" and not _HAVE_SHAPELY:\n",
    "        print(\"âš ï¸ æœªæ£€æµ‹åˆ° shapelyï¼Œå·²è‡ªåŠ¨é€€å› keep_mode='REP'ã€‚æƒ³è¦ polygon å¹¶é›†ï¼Œè¯·ï¼š pip install shapely\")\n",
    "    print(f\"âœ”ï¸ å·²ä¿å­˜åˆ° {output_json_path}ï¼ˆè¦†ç›–ï¼‰\")\n",
    "    return cleaned_annotations\n",
    "\n",
    "\n",
    "# ============== å¯è§†åŒ–ï¼ˆOpenCV å¹¶è¡Œï¼‰ ==============\n",
    "def visualize_annotations(\n",
    "    merged_annotations: Dict[str, List[Dict[str, Any]]],\n",
    "    original_image_dir: str,\n",
    "    output_visual_dir: str,\n",
    "    draw_text: bool = True,\n",
    "    jpeg_quality: int = 85,\n",
    "    parallel: bool = True,\n",
    "    max_workers: Optional[int] = None\n",
    "):\n",
    "    os.makedirs(output_visual_dir, exist_ok=True)\n",
    "    image_index = _build_image_index(original_image_dir)\n",
    "\n",
    "    tasks: List[Tuple] = []\n",
    "    for image_name, annotations in merged_annotations.items():\n",
    "        image_path = image_index.get(image_name)\n",
    "        if image_path is None or not os.path.exists(image_path):\n",
    "            # å…œåº•ï¼šå‰ç¼€åŒ¹é…ï¼ˆåªåœ¨ miss æ—¶è§¦å‘ï¼‰\n",
    "            found = None\n",
    "            for p in Path(original_image_dir).glob(f\"{image_name}*.jpg\"):\n",
    "                found = str(p); break\n",
    "            image_path = found\n",
    "        if image_path is None or not os.path.exists(image_path):\n",
    "            continue\n",
    "        tasks.append((image_name, annotations, image_path, output_visual_dir, draw_text, jpeg_quality))\n",
    "\n",
    "    if not tasks:\n",
    "        print(\"âš ï¸ æ²¡æœ‰å¯è§†åŒ–ä»»åŠ¡ï¼ˆæœªåŒ¹é…åˆ°åŸå›¾ï¼‰\")\n",
    "        return\n",
    "\n",
    "    if not parallel:\n",
    "        for t in tqdm(tasks, desc=\"Visualizing (serial)\", unit=\"image\"):\n",
    "            _draw_one_image_cv2(t)\n",
    "    else:\n",
    "        if max_workers is None:\n",
    "            max_workers = max(2, (os.cpu_count() or 8) // 2)\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "            futures = [ex.submit(_draw_one_image_cv2, t) for t in tasks]\n",
    "            for _ in tqdm(as_completed(futures), total=len(futures), desc=\"Visualizing (parallel)\", unit=\"image\"):\n",
    "                pass\n",
    "\n",
    "    print(f\"ğŸ–¼ å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åˆ° {output_visual_dir}/\")\n",
    "\n",
    "\n",
    "# ============== è£å‰ªå¯¼å‡ºï¼ˆOpenCV å¹¶è¡Œï¼‰ ==============\n",
    "def _export_one_image_objects_cv2(args: Tuple[str, List[Dict[str, Any]], str, str, int, int]) -> int:\n",
    "    \"\"\"\n",
    "    å­è¿›ç¨‹ï¼šæŒ‰ç…§ polygon çš„å¤–æ¥æ­£æ–¹å½¢è£å‰ªå¹¶ä¿å­˜ï¼ˆå¸¦ marginï¼‰\n",
    "    args = (image_name, annotations, image_path, out_dir, margin, jpeg_quality)\n",
    "    \"\"\"\n",
    "    image_name, annotations, image_path, out_dir, margin, jpeg_quality = args\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return 0\n",
    "    H, W = img.shape[:2]\n",
    "    saved = 0\n",
    "\n",
    "    for idx, ann in enumerate(annotations):\n",
    "        pts = np.asarray(ann[\"points\"], dtype=np.float32)\n",
    "        xs = pts[:, 0]; ys = pts[:, 1]\n",
    "        min_x, max_x = float(xs.min()), float(xs.max())\n",
    "        min_y, max_y = float(ys.min()), float(ys.max())\n",
    "\n",
    "        width  = max_x - min_x\n",
    "        height = max_y - min_y\n",
    "        side   = max(width, height)\n",
    "\n",
    "        cx = (min_x + max_x) * 0.5\n",
    "        cy = (min_y + max_y) * 0.5\n",
    "\n",
    "        left   = int(round(cx - side * 0.5)) - margin\n",
    "        top    = int(round(cy - side * 0.5)) - margin\n",
    "        right  = int(round(cx + side * 0.5)) + margin\n",
    "        bottom = int(round(cy + side * 0.5)) + margin\n",
    "\n",
    "        left   = max(0, left)\n",
    "        top    = max(0, top)\n",
    "        right  = min(W, right)\n",
    "        bottom = min(H, bottom)\n",
    "\n",
    "        if right - left <= 1 or bottom - top <= 1:\n",
    "            continue\n",
    "\n",
    "        crop = img[top:bottom, left:right]\n",
    "        save_name = f\"{image_name}_obj{idx}_{ann.get('label','')}_uuid_{ann['uuid']}.jpg\"\n",
    "        out_path = os.path.join(out_dir, save_name)\n",
    "        cv2.imwrite(out_path, crop, [int(cv2.IMWRITE_JPEG_QUALITY), int(jpeg_quality)])\n",
    "        saved += 1\n",
    "\n",
    "    return saved\n",
    "\n",
    "\n",
    "def export_individual_objects_cv2(\n",
    "    merged_annotations: Dict[str, List[Dict[str, Any]]],\n",
    "    original_image_dir: str,\n",
    "    cropped_object_dir: str,\n",
    "    margin: int = 0,\n",
    "    jpeg_quality: int = 85,\n",
    "    parallel: bool = True,\n",
    "    max_workers: Optional[int] = None\n",
    "):\n",
    "    os.makedirs(cropped_object_dir, exist_ok=True)\n",
    "    image_index = _build_image_index(original_image_dir)\n",
    "\n",
    "    tasks: List[Tuple] = []\n",
    "    for image_name, annotations in merged_annotations.items():\n",
    "        image_path = image_index.get(image_name)\n",
    "        if image_path is None or not os.path.exists(image_path):\n",
    "            found = None\n",
    "            for p in Path(original_image_dir).glob(f\"{image_name}*.jpg\"):\n",
    "                found = str(p); break\n",
    "            image_path = found\n",
    "        if image_path is None or not os.path.exists(image_path):\n",
    "            continue\n",
    "        tasks.append((image_name, annotations, image_path, cropped_object_dir, margin, jpeg_quality))\n",
    "\n",
    "    total = 0\n",
    "    if not tasks:\n",
    "        print(\"âš ï¸ æ²¡æœ‰å¯å¯¼å‡ºçš„è£å‰ªä»»åŠ¡ï¼ˆæœªåŒ¹é…åˆ°åŸå›¾ï¼‰\")\n",
    "        return\n",
    "\n",
    "    if not parallel:\n",
    "        for t in tqdm(tasks, desc=\"Exporting crops (serial)\", unit=\"image\"):\n",
    "            total += _export_one_image_objects_cv2(t)\n",
    "    else:\n",
    "        if max_workers is None:\n",
    "            max_workers = max(2, (os.cpu_count() or 8) // 2)\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "            futures = [ex.submit(_export_one_image_objects_cv2, t) for t in tasks]\n",
    "            for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Exporting crops (parallel)\", unit=\"image\"):\n",
    "                total += fut.result()\n",
    "\n",
    "    print(f\"ğŸ“¦ ä¸ªä½“è£å‰ªå›¾åƒå·²ä¿å­˜åˆ° {cropped_object_dir}/ ï¼ˆå…±å¯¼å‡º {total} å¼ ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for d in chosen_dirs:\n",
    "        print(f\"\\n=== å¤„ç†ç›®å½•: {d} ===\")\n",
    "        original_image_dir = str(d)\n",
    "        sliced_label_dir = str(d) + \"_sliced\"\n",
    "        output_json_path = str(d) + \"_sliced_merge/merged_annotations.json\"\n",
    "        output_visual_dir = str(d) + \"_sliced_merge/visualizations\"\n",
    "        cropped_object_dir = str(d) + \"_sliced_merge/cropped_objects\"\n",
    "\n",
    "        print(f\"åŸå›¾ç›®å½•: {original_image_dir}\")\n",
    "        print(f\"åˆ‡ç‰‡æ ‡æ³¨ç›®å½•: {sliced_label_dir}\")\n",
    "        print(f\"è¾“å‡ºåˆå¹¶æ ‡æ³¨: {output_json_path}\")\n",
    "        print(f\"è¾“å‡ºå¯è§†åŒ–ç›®å½•: {output_visual_dir}\")\n",
    "        print(f\"è¾“å‡ºè£å‰ªç›®å½•: {cropped_object_dir}\")\n",
    "\n",
    "        os.makedirs(output_visual_dir, exist_ok=True)\n",
    "        os.makedirs(cropped_object_dir, exist_ok=True)\n",
    "\n",
    "        # 1) åˆå¹¶\n",
    "        merged_annotations = merge_annotations(sliced_label_dir, output_json_path)\n",
    "\n",
    "        # 2) åå¤„ç†ï¼ˆæŒ‰éœ€åˆ‡æ¢ NMS / GREEDYNMM / NMM / LSNMSï¼›IOS/IOUï¼›REP/UNION_POLYï¼‰\n",
    "        merged_annotations = remove_duplicate_annotations(\n",
    "            merged_annotations,\n",
    "            output_json_path,\n",
    "            postprocess_type=\"NMS\",           # 'NMM'/'GREEDYNMM'/'LSNMS'/'NMS'\n",
    "            postprocess_match_metric=\"IOS\",   # 'IOU' or 'IOS'\n",
    "            postprocess_match_threshold=0.5,\n",
    "            postprocess_class_agnostic=False,\n",
    "            center_thresh=20,\n",
    "            keep_mode=\"REP\"                   # or \"UNION_POLY\"ï¼ˆéœ€ shapelyï¼‰\n",
    "        )\n",
    "\n",
    "        # 3) å¯è§†åŒ–ï¼ˆOpenCV å¹¶è¡Œï¼‰\n",
    "        visualize_annotations(\n",
    "            merged_annotations,\n",
    "            original_image_dir,\n",
    "            output_visual_dir,\n",
    "            draw_text=True,          # å…³æ‰æ›´å¿«\n",
    "            jpeg_quality=85,         # 75~85 å¤Ÿç”¨\n",
    "            parallel=True,\n",
    "            max_workers=None\n",
    "        )\n",
    "\n",
    "        # 4) å¯¼å‡ºè£å‰ªï¼ˆOpenCV å¹¶è¡Œï¼‰\n",
    "        export_individual_objects_cv2(\n",
    "            merged_annotations,\n",
    "            original_image_dir,\n",
    "            cropped_object_dir,\n",
    "            margin=15,\n",
    "            jpeg_quality=85,\n",
    "            parallel=True,\n",
    "            max_workers=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8ee64",
   "metadata": {},
   "source": [
    "# 0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/workspace/models/best_model/yolo11s-cls-best.pt\"\n",
    "\n",
    "# è§£ææ–‡ä»¶åçš„æ­£åˆ™è¡¨è¾¾å¼\n",
    "UUID_RE = re.compile(r\"uuid_([a-f0-9\\-]+)\\.jpg\", re.IGNORECASE)\n",
    "ORIG_RE = re.compile(r\"^(\\d+_\\d+_\\d+)_obj\", re.IGNORECASE)\n",
    "\n",
    "def get_probs_fields(res, name_map):\n",
    "    \"\"\"å®‰å…¨è·å– top1/top5 å­—æ®µï¼ˆç¼ºå¤±æ—¶ç»™ç©ºå€¼/ç©ºåˆ—è¡¨ï¼‰ã€‚\"\"\"\n",
    "    probs = getattr(res, \"probs\", None)\n",
    "    if probs is None:\n",
    "        return None, None, None, [], [], []\n",
    "\n",
    "    # top1\n",
    "    try:\n",
    "        top1_id = int(probs.top1)\n",
    "    except Exception:\n",
    "        top1_id = None\n",
    "    top1_name = name_map.get(top1_id) if top1_id is not None else None\n",
    "\n",
    "    # top1 conf\n",
    "    try:\n",
    "        top1_conf = float(getattr(probs.top1conf, \"item\", lambda: probs.top1conf)())\n",
    "    except Exception:\n",
    "        top1_conf = None\n",
    "\n",
    "    # top5\n",
    "    try:\n",
    "        top5_id = [int(x) for x in list(probs.top5)]\n",
    "    except Exception:\n",
    "        top5_id = []\n",
    "    top5_name = [name_map.get(i, str(i)) for i in top5_id]\n",
    "    try:\n",
    "        top5_conf = [float(x) for x in list(probs.top5conf)]\n",
    "    except Exception:\n",
    "        top5_conf = []\n",
    "\n",
    "    return top1_id, top1_name, top1_conf, top5_id, top5_name, top5_conf\n",
    "\n",
    "\n",
    "# ==== ä¸»æµç¨‹ ====\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) åŠ è½½æ¨¡å‹\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    class_names = model.names  # dict: {0: \"...\", 1: \"...\"}\n",
    "\n",
    "    for d in chosen_dirs:\n",
    "        print(f\"\\n=== å¤„ç†ç›®å½•: {d} ===\")\n",
    "        input_dir  = str(d) + \"_sliced_merge/cropped_objects/\"\n",
    "        output_json = str(d) + \"_sliced_merge/classification_predicted_results.json\"\n",
    "\n",
    "        # ç¡®ä¿è¾“å…¥ç›®å½•ä¸ä¸ºç©º\n",
    "        if not any(Path(input_dir).glob(\"*.jpg\")):\n",
    "            print(f\"âš ï¸ è¾“å…¥ç›®å½• {input_dir} æ²¡æœ‰ JPG æ–‡ä»¶ï¼Œè·³è¿‡\")\n",
    "            continue\n",
    "\n",
    "        # 2) æ‰§è¡Œé¢„æµ‹ï¼ˆUltralytics æ”¯æŒç›®å½•ï¼‰\n",
    "        results = model(input_dir)\n",
    "\n",
    "        data = []\n",
    "        counts = Counter()\n",
    "\n",
    "        for res in results:\n",
    "            path = getattr(res, \"path\", \"\")\n",
    "            fname = os.path.basename(path)\n",
    "\n",
    "            # æå– uuid / åŸå›¾å\n",
    "            uuid_match = UUID_RE.search(fname)\n",
    "            uuid_str = uuid_match.group(1) if uuid_match else None\n",
    "            orig_match = ORIG_RE.match(fname)\n",
    "            original_name = orig_match.group(1) if orig_match else None\n",
    "\n",
    "            # æ¦‚ç‡å­—æ®µ\n",
    "            top1_id, top1_name, top1_conf, top5_id, top5_name, top5_conf = get_probs_fields(res, class_names)\n",
    "            if top1_id is not None:\n",
    "                counts[top1_id] += 1\n",
    "\n",
    "            # è®°å½•ä¸€æ¡\n",
    "            data.append({\n",
    "                \"path\": path,\n",
    "                \"uuid\": uuid_str,\n",
    "                \"original_name\": original_name,\n",
    "                \"top1_id\": top1_id,\n",
    "                \"top1_name\": top1_name,\n",
    "                \"top1_conf\": top1_conf,\n",
    "                \"top5_id\": top5_id,\n",
    "                \"top5_name\": top5_name,\n",
    "                \"top5_conf\": top5_conf,\n",
    "            })\n",
    "\n",
    "        # 3) æ‰“å°ç»Ÿè®¡\n",
    "        print(\"åˆ†ç±»ç»Ÿè®¡ç»“æœï¼š\")\n",
    "        for cls_id, num in counts.items():\n",
    "            print(f\"{class_names.get(cls_id, cls_id)}: {num}\")\n",
    "        total = sum(counts.values())\n",
    "        print(f\"æ€»è®¡: {total}\")\n",
    "\n",
    "        # 4) ä¿å­˜ JSONï¼ˆä¿æŒä¸ä½ åŸæ¥ä¸€è‡´çš„ç»“æ„ï¼‰\n",
    "        with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"âœ… å·²ä¿å­˜åˆ° {output_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c4eb7",
   "metadata": {},
   "source": [
    "# 0302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import cv2\n",
    "import numpy as np\n",
    "import orjson\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# ========= JSON I/O =========\n",
    "def jload(fp: Path):\n",
    "    with fp.open(\"rb\") as f:\n",
    "        return orjson.loads(f.read())\n",
    "\n",
    "def jdump_to_file(obj, fp: Path):\n",
    "    fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with fp.open(\"wb\") as f:\n",
    "        f.write(orjson.dumps(obj))\n",
    "\n",
    "# ========= å·¥å…·å‡½æ•° =========\n",
    "def load_cls_map(path: Path) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    è¯»å–åˆ†ç±»ç»“æœï¼Œè¿”å› uuid -> item çš„æ˜ å°„ã€‚\n",
    "    å…è®¸ä¸¤ç§ç»“æ„ï¼š\n",
    "    1) {\"results\": [...]}\n",
    "    2) [ ... ]\n",
    "    item è‡³å°‘åº”åŒ…å«: {\"uuid\": \"...\", \"top1_name\": \"...\",  ...}\n",
    "    \"\"\"\n",
    "    data = jload(path)\n",
    "    if isinstance(data, dict) and \"results\" in data:\n",
    "        items = data[\"results\"]\n",
    "    elif isinstance(data, list):\n",
    "        items = data\n",
    "    else:\n",
    "        raise ValueError(\"classification_predicted_results.json ç»“æ„ä¸æ”¯æŒ\")\n",
    "    return {it[\"uuid\"]: it for it in items if \"uuid\" in it}\n",
    "\n",
    "def build_image_index(img_dir: Path) -> Dict[str, Path]:\n",
    "    index: Dict[str, Path] = {}\n",
    "    for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "        for p in img_dir.glob(ext):\n",
    "            index[p.stem] = p\n",
    "    return index\n",
    "\n",
    "def filter_annotations(\n",
    "    merged_annotations: Dict[str, List[dict]],\n",
    "    cls_map: Dict[str, dict],\n",
    "    keep: Optional[List[str]],\n",
    "    drop: Optional[List[str]],\n",
    "    relabel: bool\n",
    ") -> Tuple[Dict[str, List[dict]], Tuple[int, int, int]]:\n",
    "    out: Dict[str, List[dict]] = {}\n",
    "    kept = dropped = not_found = 0\n",
    "    keep_set = set(keep) if keep else None\n",
    "    drop_set = set(drop) if drop else None\n",
    "\n",
    "    for img, anns in tqdm(merged_annotations.items(), desc=\"ç­›é€‰æ ‡æ³¨ä¸­\", ncols=80):\n",
    "        new_list: List[dict] = []\n",
    "        for ann in anns:\n",
    "            u = ann.get(\"uuid\")\n",
    "            if not u:\n",
    "                continue\n",
    "            pred = cls_map.get(u)\n",
    "            if pred is None:\n",
    "                not_found += 1\n",
    "                continue\n",
    "\n",
    "            top1 = pred.get(\"top1_name\")\n",
    "            if keep_set is not None and top1 not in keep_set:\n",
    "                dropped += 1\n",
    "                continue\n",
    "            if drop_set is not None and top1 in drop_set:\n",
    "                dropped += 1\n",
    "                continue\n",
    "\n",
    "            if relabel and top1:\n",
    "                ann2 = dict(ann)\n",
    "                ann2[\"label\"] = top1\n",
    "                new_list.append(ann2)\n",
    "            else:\n",
    "                new_list.append(ann)\n",
    "            kept += 1\n",
    "\n",
    "        if new_list:\n",
    "            out[img] = new_list\n",
    "\n",
    "    return out, (kept, dropped, not_found)\n",
    "\n",
    "# ========= å¯è§†åŒ– =========\n",
    "LINE_COLOR_BGR = (0, 255, 255)\n",
    "LINE_WIDTH = 1\n",
    "TEXT_SCALE = 0.7\n",
    "TEXT_THICKNESS = 2\n",
    "TEXT_COLOR_BGR = (0, 255, 255)\n",
    "TEXT_FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "TEXT_DY = 18\n",
    "\n",
    "def _draw_one_image(image_name: str, anns: List[dict], img_index: Dict[str, str], out_dir: str):\n",
    "    img_path = img_index.get(image_name) or img_index.get(Path(image_name).stem)\n",
    "    if not img_path:\n",
    "        return None\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    for i, ann in enumerate(anns):\n",
    "        pts = ann[\"points\"]\n",
    "        pts_np = np.asarray(pts, dtype=np.int32).reshape(-1, 1, 2)\n",
    "        cv2.polylines(img, [pts_np], True, LINE_COLOR_BGR, LINE_WIDTH)\n",
    "\n",
    "        label = str(ann.get(\"label\", \"\"))\n",
    "        s = ann.get(\"score\")\n",
    "        label_txt = f\"{label} {s:.3f}\" if isinstance(s, (float, int)) else label\n",
    "        x0, y0 = int(pts[0][0]), int(pts[0][1])\n",
    "        cv2.putText(img, label_txt, (x0 + 6, y0 + 6 + (i % 3) * TEXT_DY),\n",
    "                    TEXT_FONT, TEXT_SCALE, TEXT_COLOR_BGR, TEXT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    out_path = str(Path(out_dir) / f\"{Path(image_name).stem}_vis.jpg\")\n",
    "    cv2.imwrite(out_path, img, [int(cv2.IMWRITE_JPEG_QUALITY), 85])\n",
    "    return out_path\n",
    "\n",
    "def visualize_parallel(annotations: Dict[str, List[dict]], original_dir: Path, out_dir: Path, max_workers: int):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    img_index = {k: str(v) for k, v in build_image_index(original_dir).items()}\n",
    "    total = len(annotations)\n",
    "    if total == 0:\n",
    "        return\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = [\n",
    "            ex.submit(_draw_one_image, image_name, anns, img_index, str(out_dir))\n",
    "            for image_name, anns in annotations.items()\n",
    "        ]\n",
    "        for _ in tqdm(as_completed(futures), total=total, desc=\"å¯è§†åŒ–ä¸­\", ncols=80):\n",
    "            pass\n",
    "\n",
    "# ========= å°å›¾æ•´ç†ï¼ˆå« othersï¼‰=========\n",
    "_UUID_RE = re.compile(r\"uuid_([a-f0-9\\-]+)\\.(jpg|jpeg|png)$\", re.IGNORECASE)\n",
    "\n",
    "def sort_cropped_objects(\n",
    "    cropped_dir: Path,\n",
    "    out_root: Path,\n",
    "    cls_map: Dict[str, dict],\n",
    "    keep: Optional[List[str]],\n",
    "    drop: Optional[List[str]],\n",
    "    max_workers: int\n",
    ") -> Tuple[int, int, int, int, Counter]:\n",
    "    \"\"\"\n",
    "    å°† cropped_objects é‡Œçš„å›¾ç‰‡æŒ‰ top1_name å½’ç±»å¤åˆ¶åˆ° out_root/<class_name>/ ä¸‹ï¼Œ\n",
    "    æœªå‘½ä¸­ keep/drop æˆ–æ— é¢„æµ‹ / æ–‡ä»¶åä¸åŒ¹é…çš„ï¼Œç»Ÿä¸€æ”¾åˆ° out_root/others/ ä¸‹ã€‚\n",
    "    è¿”å›: (æ€»æ–‡ä»¶æ•°, ç¬¦åˆæ¡ä»¶å¤åˆ¶æ•°, æ— é¢„æµ‹æ•°, othersæ•°, å„ç±»åˆ«è®¡æ•°)\n",
    "    \"\"\"\n",
    "    if not cropped_dir.exists():\n",
    "        print(f\"âš ï¸ æœªæ‰¾åˆ°è£å‰ªç›®å½•: {cropped_dir}\")\n",
    "        return 0, 0, 0, 0, Counter()\n",
    "\n",
    "    files: List[Path] = []\n",
    "    for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "        files.extend(cropped_dir.glob(ext))\n",
    "    total = len(files)\n",
    "    if total == 0:\n",
    "        print(f\"âš ï¸ è£å‰ªç›®å½•ä¸ºç©º: {cropped_dir}\")\n",
    "        return 0, 0, 0, 0, Counter()\n",
    "\n",
    "    copied_kept = 0\n",
    "    no_pred = 0\n",
    "    others = 0\n",
    "    per_class = Counter()\n",
    "    keep_set = set(keep) if keep else None\n",
    "    drop_set = set(drop) if drop else None\n",
    "\n",
    "    def to_dir(d: Path):\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "        return d\n",
    "\n",
    "    def task(path: Path):\n",
    "        nonlocal copied_kept, no_pred, others\n",
    "        m = _UUID_RE.search(path.name)\n",
    "        if not m:\n",
    "            # æ–‡ä»¶åä¸ç¬¦åˆè§„åˆ™ â†’ others\n",
    "            dst = to_dir(out_root / \"others\")\n",
    "            shutil.copy2(path, dst / path.name)\n",
    "            per_class.update([\"others\"])\n",
    "            others += 1\n",
    "            return\n",
    "\n",
    "        uuid = m.group(1)\n",
    "        pred = cls_map.get(uuid)\n",
    "        if pred is None:\n",
    "            # æ— é¢„æµ‹ â†’ others\n",
    "            dst = to_dir(out_root / \"others\")\n",
    "            shutil.copy2(path, dst / path.name)\n",
    "            per_class.update([\"others\"])\n",
    "            others += 1\n",
    "            no_pred += 1\n",
    "            return\n",
    "\n",
    "        top1 = pred.get(\"top1_name\")\n",
    "        # è§„åˆ™åˆ¤æ–­\n",
    "        if keep_set is not None and top1 not in keep_set:\n",
    "            dst = to_dir(out_root / \"others\")\n",
    "            shutil.copy2(path, dst / path.name)\n",
    "            per_class.update([\"others\"])\n",
    "            others += 1\n",
    "            return\n",
    "        if drop_set is not None and top1 in drop_set:\n",
    "            dst = to_dir(out_root / \"others\")\n",
    "            shutil.copy2(path, dst / path.name)\n",
    "            per_class.update([\"others\"])\n",
    "            others += 1\n",
    "            return\n",
    "\n",
    "        # âœ… ç¬¦åˆæ¡ä»¶ï¼Œå¤åˆ¶åˆ°å¯¹åº”ç±»åˆ«\n",
    "        subdir = top1 or \"unknown\"\n",
    "        dst = to_dir(out_root / subdir)\n",
    "        shutil.copy2(path, dst / path.name)\n",
    "        per_class.update([subdir])\n",
    "        copied_kept += 1\n",
    "\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        list(tqdm(ex.map(task, files), total=total, desc=\"æ•´ç†å°å›¾ä¸­\", ncols=80))\n",
    "\n",
    "    return total, copied_kept, no_pred, others, per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d036fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ---- è¿‡æ»¤ç­–ç•¥ ----\n",
    "    DROP_CLASSES: Optional[List[str]] = None\n",
    "    KEEP_CLASSES: Optional[List[str]] = [\"swd\"]\n",
    "    RENAME_WITH_PRED: bool = True\n",
    "\n",
    "    # ---- å¼€å…³ä¸å¹¶å‘ ----\n",
    "    DO_VISUALIZE = True\n",
    "    DO_SORT_CROPPED = True\n",
    "    MAX_WORKERS = min(max(1, (os.cpu_count() or 2) - 1), 8)\n",
    "\n",
    "\n",
    "    for d in chosen_dirs:\n",
    "        print(f\"\\n=== å¤„ç†ç›®å½•: {d} ===\")   \n",
    "        \n",
    "        # ---- è·¯å¾„é…ç½® ----\n",
    "        CLASSIFICATION_JSON = d.parent / (d.name + \"_sliced_merge\") / \"classification_predicted_results.json\"\n",
    "        MERGED_ANN_JSON     = d.parent / (d.name + \"_sliced_merge\") / \"merged_annotations.json\"\n",
    "        FILTERED_ANN_JSON   = d.parent / (d.name + \"_sliced_merge\") / \"filtered_annotations.json\"\n",
    "        ORIGINAL_IMAGE_DIR  = d.parent / (d.name)\n",
    "        OUT_VIS_DIR         = d.parent / (d.name + \"_sliced_merge\") / \"filtered_visualizations\"\n",
    "        CROPPED_OBJECTS_DIR = d.parent / (d.name + \"_sliced_merge\") / \"cropped_objects\"\n",
    "        FILTERED_CROPPED_DIR= d.parent / (d.name + \"_sliced_merge\") / \"filtered_cropped_objects\"\n",
    "\n",
    "        # ç¡®ä¿è·¯å¾„å­˜åœ¨\n",
    "        if not any(ORIGINAL_IMAGE_DIR.glob(\"*.jpg\")):\n",
    "            print(f\"âš ï¸ è·³è¿‡ï¼ŒåŸå›¾ç›®å½•ä¸å­˜åœ¨æˆ–æ— å›¾ç‰‡: {ORIGINAL_IMAGE_DIR}\")\n",
    "            continue\n",
    "\n",
    "        # è¯»å–åˆ†ç±»ä¸åˆå¹¶æ ‡æ³¨\n",
    "        cls_map = load_cls_map(CLASSIFICATION_JSON)\n",
    "        merged = jload(MERGED_ANN_JSON)\n",
    "\n",
    "        # ç­›é€‰æ ‡æ³¨å¹¶å¯é€‰é‡æ ‡\n",
    "        filtered, (kept, dropped, not_found) = filter_annotations(\n",
    "            merged_annotations=merged,\n",
    "            cls_map=cls_map,\n",
    "            keep=KEEP_CLASSES,\n",
    "            drop=DROP_CLASSES,\n",
    "            relabel=RENAME_WITH_PRED\n",
    "        )\n",
    "        print(f\"\\n[æ ‡æ³¨ç­›é€‰ç»Ÿè®¡] kept: {kept}, dropped: {dropped}, uuid_without_pred: {not_found}\")\n",
    "\n",
    "        jdump_to_file(filtered, FILTERED_ANN_JSON)\n",
    "        print(f\"âœ… å·²ä¿å­˜ç­›é€‰åçš„æ ‡æ³¨: {FILTERED_ANN_JSON}\")\n",
    "\n",
    "        # å¯è§†åŒ–\n",
    "        if DO_VISUALIZE:\n",
    "            visualize_parallel(filtered, ORIGINAL_IMAGE_DIR, OUT_VIS_DIR, max_workers=MAX_WORKERS)\n",
    "            print(f\"âœ… å·²ä¿å­˜å¯è§†åŒ–ç»“æœ: {OUT_VIS_DIR}\")\n",
    "\n",
    "        # å°å›¾åˆ†ç±»ï¼ˆå« othersï¼‰\n",
    "        if DO_SORT_CROPPED:\n",
    "            total, copied_kept, no_pred, others, per_class = sort_cropped_objects(\n",
    "                CROPPED_OBJECTS_DIR,\n",
    "                FILTERED_CROPPED_DIR,\n",
    "                cls_map=cls_map,\n",
    "                keep=KEEP_CLASSES,\n",
    "                drop=DROP_CLASSES,\n",
    "                max_workers=MAX_WORKERS\n",
    "            )\n",
    "            print(\"\\n[è£å‰ªå°å›¾æ•´ç†ç»Ÿè®¡]\")\n",
    "            print(f\"  æ€»è®¡æ‰«æ: {total}\")\n",
    "            print(f\"  ç¬¦åˆè§„åˆ™å¹¶å½’ç±»: {copied_kept}\")\n",
    "            print(f\"  æ— é¢„æµ‹æ”¾å…¥ others: {no_pred}\")\n",
    "            print(f\"  å…¶ä½™ï¼ˆä¸åœ¨ keep æˆ–å‘½ä¸­ dropã€æ–‡ä»¶åä¸åˆè§„ç­‰ï¼‰æ”¾å…¥ others: {others - no_pred}\")\n",
    "            if per_class:\n",
    "                print(\"  å„ç±»åˆ«è®¡æ•°ï¼š\")\n",
    "                for k, v in per_class.most_common():\n",
    "                    print(f\"    {k}: {v}\")\n",
    "            print(f\"âœ… å·²åˆ†ç±»ä¿å­˜åˆ°: {FILTERED_CROPPED_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
